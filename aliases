alias iadnode_connect='ssh -i iadnode.pem bitnami@34.148.204.101'

#UPa
#sudo 7z x reports.rar -o/opt/bitnami/apache2/htdocs/kraken
#sudo apt install p7zip-full

fastpush() {
  # Si no se pasa mensaje, error y salir
  if [ -z "$1" ]; then
    echo "‚ùå  Debes pasar un mensaje de commit."
    echo "üëâ  Uso: fastpush \"mensaje del commit\""
    return 1
  fi

  # Guarda el mensaje completo (por si contiene espacios)
  local msg="$*"

  echo "üì¶ Agregando archivos..."
  git add .

  echo "üìù Commit con mensaje: \"$msg\""
  git commit -m "$msg" || {
    echo "‚ö†Ô∏è  No hay cambios para commitear."
    return 0
  }

  echo "üöÄ Haciendo push..."
  git push

  echo "‚úÖ  Fastpush completado."
}

linux_version() {
    cat /etc/os-release
}

nano_install(){
    apt update && apt install nano -y
}

ssh_zip() {
    if [ -z "$1" ]; then
        echo "Usage: ssh_zip <foldername>"
        return 1
    fi
    sudo tar -czvf "$1".tgz "$1"/
}

python_serve(){
    python -m http.server 8000
}




flask_run() {
    clear
    flask run
}

flask_restart(){
    clear    
    sudo rm -f ../instance/*.sqlite ../instance/*.db
    flask run
}

bashrc_refresh(){
    cd ~/bashrc
    git pull
    . ~/.bashrc    
    cd -
}

test_all(){
    python -m unittest discover
}

watchdog(){
    watchmedo shell-command --patterns="*.py" --recursive command='python -m unittest discover -s tests -v' .
}

watchdog_always(){
    nohup watchmedo shell-command --patterns="*.py" --recursive --command='python -m unittest discover -s tests -v' . &
}

port_check() {
    sudo lsof -i :"$1"
}

port_kill() {
    sudo kill -9 "$1"
}

ssh_iniciar() {
    eval "$(ssh-agent -s)"
}

ssh_generar() {
  if [ -z "$1" ]; then
    echo "‚ùå Error: Debes proporcionar un nombre para la clave."
    return 1
  fi

  # Definir el nombre del archivo de la clave
  local nombre_clave="$1"
  
  echo "üîë Iniciando la generaci√≥n de la clave SSH sin contrase√±a..."

  # Mensaje sobre los par√°metros recibidos
  echo "üìù Nombre de la clave: $nombre_clave"
  echo "üîí La clave no tendr√° contrase√±a."

  # Generar la clave SSH ED25519 sin passphrase
  echo "‚öôÔ∏è Generando clave SSH con el algoritmo ED25519..."
  ssh-keygen -t ed25519 -C "$nombre_clave" -f "$HOME/.ssh/$nombre_clave" -N ""

  # Verificar si la clave p√∫blica fue generada
  local pub_key="$HOME/.ssh/${nombre_clave}.pub"
  if [ -f "$pub_key" ]; then
    echo "‚úÖ Clave SSH generada con √©xito para '$nombre_clave'."

    # Mostrar contenido de la clave p√∫blica
    echo "üìú Contenido de la clave p√∫blica generada:"
    cat "$pub_key"

    echo "üéâ ¬°La clave p√∫blica ha sido mostrada exitosamente!"
  else
    echo "‚ùå Error: No se pudo generar la clave p√∫blica. Revisa los errores anteriores."
    return 1
  fi
}

ssh_activar() {
    
    if [ -z "$1" ]; then
        echo "Usage: ssh_activar <key_filename>"
        return 1
    fi
    eval "$(ssh-agent -s)"
    ssh-add ~/.ssh/"$1"
}

tree_list(){
    tree -I 'node_modules|venv|.git|__pycache__|dist|build|.pytest_cache|.vscode|.idea|coverage' -a
}

tree_install(){
    sudo apt install tree -y
}
########################################################################################## PYTHON
pyenv_install() {
    echo "üîß Actualizando paquetes..."
    sudo apt update -y

    echo "üì¶ Instalando dependencias..."
    sudo apt install -y make build-essential libssl-dev zlib1g-dev \
        libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm \
        libncurses5-dev libncursesw5-dev xz-utils tk-dev \
        libffi-dev liblzma-dev git

    echo "‚¨áÔ∏è Instalando pyenv..."
    curl https://pyenv.run | bash

    echo "‚öôÔ∏è Configurando variables en ~/.bashrc..."
    if ! grep -q 'pyenv init' ~/.bashrc; then
        cat <<'EOF' >> ~/.bashrc

# >>> pyenv configuration >>>
export PATH="$HOME/.pyenv/bin:$PATH"
eval "$(pyenv init --path)"
eval "$(pyenv init -)"
eval "$(pyenv virtualenv-init -)"
# <<< pyenv configuration <<<
EOF
    fi

    echo "üîÑ Recargando configuraci√≥n..."
    source ~/.bashrc

    echo "‚úÖ Instalaci√≥n completada. Versi√≥n de pyenv:"
    pyenv --version
}

pyenv_local() {
  local version=$1
  if [ -z "$version" ]; then
    echo "‚ùå Debes pasar una versi√≥n. Ejemplo: set_pyenv_local 3.11.9"
    return 1
  fi

  # Verificar si ya est√° instalada
  if ! pyenv versions --bare | grep -q "^${version}\$"; then
    echo "üîç Python $version no est√° instalado. Instalando..."
    pyenv install "$version"
  else
    echo "‚úÖ Python $version ya est√° instalado."
  fi

  # Configurar como local
  pyenv local "$version"
  echo "üìå Se configur√≥ Python $version como versi√≥n local en $(pwd)"
}

pyenv_version() {
  if ! command -v pyenv >/dev/null 2>&1; then
    echo "‚ùå pyenv no est√° instalado o no est√° en el PATH."
    return 1
  fi

  echo "üêç Versi√≥n activa de Python con pyenv:"
  pyenv exec python -V
}

pyenv_venv() {
    if [ -z "$1" ]; then
        echo "‚ùå Debes pasar el nombre del environment como par√°metro"
        echo "üëâ Ejemplo: make_env myproject"
        return 1
    fi

    ENV_NAME="$1"
    ENV_DIR=".$ENV_NAME"

    echo "üöÄ Creando environment en $ENV_DIR ..."
    pyenv exec python -m venv "$ENV_DIR"

    echo "‚úÖ Environment creado: $ENV_DIR"
    echo "üëâ Act√≠valo con: source $ENV_DIR/bin/activate"
}

pyenv_activate_venv() {
    if [ -z "$1" ]; then
        echo "‚ùå Debes pasar el nombre del environment como par√°metro"
        echo "üëâ Ejemplo: activate_env venv"
        return 1
    fi

    ENV_NAME="$1"
    ENV_DIR=".$ENV_NAME"

    if [ ! -d "$ENV_DIR" ]; then
        echo "‚ùå El environment $ENV_DIR no existe."
        echo "üëâ Primero cr√©alo con: make_env $ENV_NAME"
        return 1
    fi

    echo "‚ö° Activando environment: $ENV_DIR ..."
    source "$ENV_DIR/bin/activate"
}

pyenv_gitignore() {
  local file=".gitignore"

  cat > "$file" <<EOF
# ========================
# Archivos Python compilados
# ========================
*.pyc
*.pyo
*.pyd
__pycache__/

# ========================
# Entornos virtuales
# ========================
.env
.venv/
env/
venv/
ENV/

# ========================
# Bases de datos
# ========================
*.db
*.sqlite3

# ========================
# Archivos de pruebas
# ========================
.coverage
coverage.xml
*.cover
*.py,cover
.pytest_cache/
htmlcov/
.tox/
.nox/

# ========================
# Distribuci√≥n / empaquetado
# ========================
build/
dist/
*.egg-info/
.eggs/

# ========================
# Logs
# ========================
*.log

# ========================
# IDEs / Editores
# ========================
.vscode/
.idea/

# ========================
# Archivos del sistema
# ========================
.DS_Store
Thumbs.db

# ========================
# Im√°genes y binarios
# ========================
*.png
*.jpg
*.jpeg
*.gif
*.svg
*.ico

# ========================
# Otros
# ========================
*.bak
*.tmp
EOF

  echo "‚úÖ Archivo $file sobrescrito en $(pwd)"
}

pyenv_create_settings() {
    CONFIG_DIR=".vscode"
    CONFIG_FILE="$CONFIG_DIR/settings.json"

    # Crear carpeta .vscode si no existe
    mkdir -p "$CONFIG_DIR"

    # Crear archivo settings.json con la configuraci√≥n
    cat > "$CONFIG_FILE" <<EOL
{
    "[python]": {
        "editor.codeActionsOnSave": {
            "source.organizeImports": "explicit",
            "source.fixAll": "explicit"
        }
    },
    "editor.formatOnSave": true,
    "editor.defaultFormatter": "charliermarsh.ruff"
}
EOL

    echo "‚úÖ Archivo de configuraci√≥n creado en $CONFIG_FILE"
}

pycache_delete(){
    find . -type d -name "__pycache__" -exec rm -r {} +
}

pytestcache_delete(){
    find . -type d -name ".pytest_cache" -exec rm -r {} +
}

########################################################################################## UVICORN
uvicorn_run() {
  PACKAGE=${1:-"storeapi"}       # Nombre del paquete (impl√≠citamente usa main:app)
  HOST=${2:-"127.0.0.1"}         # Host por defecto
  PORT=${3:-8000}                # Puerto por defecto
  WORKERS=${4:-1}                # N√∫mero de workers por defecto
  RELOAD=${5:-"--reload"}        # Por defecto en modo desarrollo

  APP="$PACKAGE.main:app"        # Construcci√≥n impl√≠cita

  echo "üöÄ Iniciando Uvicorn con APP=$APP en $HOST:$PORT con $WORKERS worker(s) $RELOAD"
  uvicorn $APP --host $HOST --port $PORT --workers $WORKERS $RELOAD
}

########################################################################################## FASTAPI

fastapi_install() {
    if [ -z "$VIRTUAL_ENV" ]; then
        echo "‚ö†Ô∏è No hay ning√∫n entorno virtual activado."
        echo "üëâ Primero activa tu venv con: source .venv/bin/activate"
        return 1
    fi

    echo "üì¶ Instalando FastAPI y Uvicorn en $VIRTUAL_ENV..."
    pip install --upgrade pip
    pip install fastapi uvicorn

    echo "üéâ FastAPI y Uvicorn instalados correctamente"
}

########################################################################################## REQUIREMENTS

requirements_install() {
    REQ_FILE=${1:-"requirements.txt"}  # Usa requirements.txt por defecto si no se pasa nada

    echo "üì¶ Instalando dependencias desde $REQ_FILE..."
    pip install --upgrade pip
    pip install -r "$REQ_FILE"
    echo "‚úÖ Dependencias instaladas desde $REQ_FILE."
}

requirements_generate() {
    echo "üìÑ Generando requirements.txt..."
    pip freeze > requirements.txt
    echo "‚úÖ requirements.txt actualizado."
}


########################################################################################## NPM
npm_list(){
    npm list -g --depth=0
}
npm_install(){
    if [ -z "$1" ]; then
        echo "Usage: npm_install <packageName>"
        return 1
    fi
    sudo npm install -g "$1"
}
npm_uninstall(){
    if [ -z "$1" ]; then
        echo "Usage: npm_uninstall <packageName>"
        return 1
    fi
    sudo npm uninstall -g "$1"
}
npx_list(){
    npm list --depth=0
}
npx_install(){
    if [ -z "$1" ]; then
        echo "Usage: npx_install <packageName>"
        return 1
    fi
    npm install "$1"
}
npx_uninstall(){
    if [ -z "$1" ]; then
        echo "Usage: npx_uninstall <packageName>"
        return 1
    fi
    npm uninstall "$1"
}

########################################################################################## GIT
git_email() {
    if [ -z "$1" ]; then
        echo "Uso: git_set_email \"correo@example.com\""
        return 1
    fi
    git config --global user.email "$1"
    echo "Correo de Git configurado como: $1"
}

git_name() {
    if [ -z "$1" ]; then
        echo "Uso: git_set_name \"Tu Nombre\""
        return 1
    fi
    git config --global user.name "$1"
    echo "Nombre de Git configurado como: $1"
}



########################################################################################## DOCKER

docker_restart(){
  docker compose build --no-cache && docker compose up
}

docker_networks(){
    sudo docker network ls

}

docker_networks_create(){
    if [ -z "$1" ]; then
        echo "Usage: cdocker_networks_create <network_name>"
        return 1
    fi

    NETWORK_NAME="$1"

    if sudo docker network inspect "$NETWORK_NAME" >/dev/null 2>&1; then
        echo "Network '$NETWORK_NAME' already exists."
    else
        sudo docker network create "$NETWORK_NAME"
        echo "Network '$NETWORK_NAME' created successfully."
    fi
}

docker_networks_delete(){
        if [ -z "$1" ]; then
        echo "Usage: docker_networks_delete <network_name | all>"
        return 1
    fi

    NETWORK_NAME="$1"

    if [ "$NETWORK_NAME" == "all" ]; then
        echo "Deleting all user-defined Docker networks..."
        # List all user-defined networks (excluding 'bridge', 'host', 'none') and delete them
        for net in $(sudo docker network ls --format "{{.Name}}" --filter "driver=bridge"); do
            if [[ "$net" != "bridge" && "$net" != "host" && "$net" != "none" ]]; then
                echo "Deleting network: $net"
                sudo docker network rm "$net"
            fi
        done
        echo "All user-defined networks deleted successfully."
    else
        # Check if the specific network exists
        if sudo docker network inspect "$NETWORK_NAME" >/dev/null 2>&1; then
            # Check if any containers are connected to the network
            if [ "$(sudo docker network inspect --format='{{range .Containers}}{{.Name}} {{end}}' "$NETWORK_NAME")" ]; then
                echo "Error: Network '$NETWORK_NAME' has active containers. Remove them first."
                return 1
            fi

            # Remove the network
            sudo docker network rm "$NETWORK_NAME"
            echo "Network '$NETWORK_NAME' deleted successfully."
        else
            echo "Network '$NETWORK_NAME' does not exist."
        fi
    fi
}

docker_c(){
    sudo docker ps -a
}

docker_c_run() {
    if [ -z "$1" ] || [ -z "$2" ] || [ -z "$3" ] || [ -z "$4" ]; then
        echo "Usage: docker_c_run <originPort> <destinationPort> <image_name> <container_name>"
        return 1
    fi
    sudo docker run -d -p "$2:$1" --name "$4" "$3"
}

docker_c_run_in_network() {
    if [ -z "$1" ] || [ -z "$2" ] || [ -z "$3" ] || [ -z "$4" ] || [ -z "$5" ]; then
        echo "Usage: docker_run <originPort> <destinationPort> <image_name> <container_name> <network>"
        return 1
    fi

    CUSTOM_URL="$5"  # Set the custom URL to the 5th parameter (network name)
    
    sudo docker run --network "$5" -p "$2:$1" --name "$4" -e CUSTOM_URL="$CUSTOM_URL" "$3"
}


docker_c_run_always() {
    if [ -z "$1" ] || [ -z "$2" ] || [ -z "$3" ] || [ -z "$4" ]; then
        echo "Usage: docker_run <originPort> <destinationPort> <image_name> <container_name>"
        return 1
    fi
    sudo docker run -dp "$2":"$1" --name "$4" -w /app -v "$(pwd):/app" "$3"   
}

docker_c_run_always_in_network() {
    if [ -z "$1" ] || [ -z "$2" ] || [ -z "$3" ] || [ -z "$4" ] || [ -z "$5" ]; then
        echo "Usage: docker_run <originPort> <destinationPort> <image_name> <container_name> <network>"
        return 1
    fi
    sudo docker run -dp "$2:$1" --network "$5" --name "$4" -w /app -v "$(pwd):/app" "$3" tail -f /dev/null
}


docker_c_start() {
    if [ "$1" == "all" ]; then
        echo "Starting all stopped containers..."
        sudo docker start $(sudo docker ps -aq)
    else
        echo "Starting container: $1"
        sudo docker start "$1"
    fi
}

docker_c_stop() {
    if [ -z "$1" ]; then
        echo "Usage: docker_c_stop <container_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker stop $(sudo docker ps -q)
    else
        sudo docker stop "$1"
    fi
}

docker_c_restart() {
    if [ -z "$1" ]; then
        echo "Usage: docker_c_restart <container_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker restart $(sudo docker ps -q)
    else
        sudo docker restart "$1"
    fi
}

docker_c_delete() {
    if [ -z "$1" ]; then
        echo "Usage: docker_delete <container_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker rm $(sudo docker ps -aq)
    else
        sudo docker rm "$1"
    fi
}

docker_c_logs(){
    if [ -z "$1" ]; then
        echo "Usage: docker_c_logs <container_name_or_id>"
        return 1
    fi
    sudo docker logs -f "$1"
}

docker_c_enter(){
    if [ -z "$1" ]; then
        echo "Usage: docker_c_enter <container_name_or_id>"
        return 1
    fi
    sudo docker exec -it "$1" sh
}

docker_i(){
    sudo docker images
}

docker_i_build() {
    if [ -z "$1" ]; then
        echo "Usage: docker_build <image_name>"
        return 1
    fi
    sudo docker build --network=host -t "$1" .
}

docker_i_delete() {
    if [ -z "$1" ]; then
        echo "Usage: docker_delete_image <image_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker rmi $(sudo docker images -q)
    else
        sudo docker rmi "$1"
    fi
}

docker_i_delete_forced() {
    if [ -z "$1" ]; then
        echo "Usage: docker_delete_image <image_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker rmi -f $(sudo docker images -q)
    else
        sudo docker rmi -f "$1"
    fi
}

docker_i_compose() {
    sudo docker compose up
}

docker_i_compose_forced() {
    if [ -z "$1" ]; then
        echo "Usage: docker_i_compose_forced <service_name>"
        return 1
    fi
    sudo docker compose up --build --force-recreate --no-deps "$1"
}

docker_i_pull() {
    if [ -z "$1" ]; then
        echo "Usage: docker_i_pull <image_name> <version (opcional)>"
        return 1
    fi
    sudo docker image pull "$1:${2:-latest}"
}

docker_install() {
    OS=$1                 # 'debian' o 'ubuntu'
    TARGET_USER=${2:-$USER}  # usuario al que darle permisos (default: usuario actual)

    if [[ "$OS" != "debian" && "$OS" != "ubuntu" ]]; then
        echo "Error: Debes especificar 'debian' o 'ubuntu' como primer par√°metro."
        return 1
    fi

    if ! id -u "$TARGET_USER" >/dev/null 2>&1; then
        echo "Error: el usuario '$TARGET_USER' no existe en el sistema."
        return 1
    fi

    set -euo pipefail
    echo ">>> Instalando Docker en $OS para el usuario: $TARGET_USER"

    # Paquetes base y llave del repo oficial
    sudo apt-get update
    sudo apt-get install -y ca-certificates curl gnupg lsb-release
    sudo install -m 0755 -d /etc/apt/keyrings
    if [[ ! -f /etc/apt/keyrings/docker.asc ]]; then
        sudo curl -fsSL "https://download.docker.com/linux/$OS/gpg" -o /etc/apt/keyrings/docker.asc
        sudo chmod a+r /etc/apt/keyrings/docker.asc
    fi

    # Agregar repo estable
    CODENAME="$(. /etc/os-release && echo "$VERSION_CODENAME")"
    echo ">>> Usando codename: $CODENAME"
    echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/$OS $CODENAME stable" \
      | sudo tee /etc/apt/sources.list.d/docker.list >/dev/null

    # Instalar Docker + Buildx + Compose v2
    sudo apt-get update
    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

    # Habilitar y arrancar Docker
    sudo systemctl enable --now docker

    # Crear grupo docker si no existe y agregar usuario
    if ! getent group docker >/dev/null; then
        sudo groupadd docker
    fi
    sudo usermod -aG docker "$TARGET_USER"

    # Ajustar permisos del socket (para que funcione de inmediato en esta sesi√≥n)
    if [[ -S /var/run/docker.sock ]]; then
        sudo chown root:docker /var/run/docker.sock
        sudo chmod 660 /var/run/docker.sock
    fi

    # Verificaci√≥n b√°sica
    echo ">>> Verificaci√≥n:"
    docker --version || true
    docker compose version || true

    # Intentar ejecutar como el usuario objetivo sin re-login
    if sudo -u "$TARGET_USER" docker ps >/dev/null 2>&1; then
        echo "‚úÖ $TARGET_USER puede usar docker sin sudo."
    else
        # Intentar con 'sg docker' si est√° disponible (aplica el grupo en caliente)
        if command -v sg >/dev/null 2>&1; then
            if sudo -u "$TARGET_USER" sg docker -c 'docker ps' >/dev/null 2>&1; then
                echo "‚úÖ $TARGET_USER puede usar docker v√≠a 'sg docker' en esta sesi√≥n."
            else
                echo "‚ÑπÔ∏è A√∫n no es posible usar docker sin sudo en esta sesi√≥n."
            fi
        else
            echo "‚ÑπÔ∏è 'sg' no disponible; puede requerir re-login para aplicar el grupo."
        fi
        echo "üëâ Mientras tanto, puedes usar: sudo docker ..."
    fi

    echo "‚úÖ Instalaci√≥n completa. Si a√∫n no puedes usar 'docker' sin sudo, cierra y vuelve a entrar sesi√≥n de $TARGET_USER."
}

docker_clean(){
    sudo docker system prune -a --volumes
}

########################################################################################## GHOST

MAILGUN_USER="brad@sandbox27703646c4a5406f948c2ed685c84070.mailgun.org"
MAILGUN_API_KEY="27450cd34c15e02c3830faae0f41ff63-67bd41c2-c8b32c62"

ghost_terminal(){
    sudo docker exec -it ghost /bin/bash
}

install_jq_in_container() {
    echo "üîß Instalando jq dentro del contenedor Ghost..."
    sudo docker exec ghost bash -c "apt-get update && apt-get install -y jq"
}

replace_mail_config() {
    local config_file=$1

    echo "Verificando existencia del archivo en el contenedor: $config_file"
    sudo docker exec ghost ls "$config_file"

    if [ $? -ne 0 ]; then
        echo "El archivo $config_file no existe en el contenedor."
        return 1
    fi

    echo "Reemplazando la configuraci√≥n de mail en $config_file con jq..."

    sudo docker exec ghost bash -c "jq \
    '.mail = {
        transport: \"SMTP\",
        options: {
            service: \"Mailgun\",
            host: \"smtp.mailgun.org\",
            port: 587,
            secure: false,
            auth: {
                user: \"${MAILGUN_USER}\",
                pass: \"${MAILGUN_API_KEY}\"
            }
        }
    }' $config_file > /tmp/config.tmp && mv /tmp/config.tmp $config_file"

    echo "‚úÖ Configuraci√≥n de mail reemplazada usando jq."
}

ghost_run() {
    # Par√°metro: versi√≥n de Ghost
    GHOST_VERSION=$1

    # Nombre fijo para el contenedor y puerto est√°ndar
    CONTAINER_NAME="ghost"
    IMAGE_NAME="ghost:${GHOST_VERSION}"
    HOST_PORT=2368
    CONTAINER_PORT=2368

    echo "üß≠ Verificando existencia del contenedor '${CONTAINER_NAME}'..."

    if [ "$(sudo docker ps -a -q -f name=^/${CONTAINER_NAME}$)" ]; then
        echo "‚õî Contenedor '${CONTAINER_NAME}' encontrado. Deteniendo y eliminando..."
        sudo docker stop ${CONTAINER_NAME}
        sudo docker rm ${CONTAINER_NAME}
    else
        echo "‚ÑπÔ∏è No existe un contenedor llamado '${CONTAINER_NAME}'."
    fi

    echo "üßπ Limpiando vol√∫menes sin uso..."
    sudo docker volume prune -f

    echo "üì¶ Levantando Ghost ${GHOST_VERSION} en http://localhost:${HOST_PORT}..."
    sudo docker run -d \
        --name ${CONTAINER_NAME} \
        -e NODE_ENV=development \
        -p ${HOST_PORT}:${CONTAINER_PORT} \
        ${IMAGE_NAME}

    echo "‚úÖ Ghost ${GHOST_VERSION} corriendo en http://localhost:${HOST_PORT}"
}


cypress_run() {
    # Recibir la versi√≥n de Ghost como par√°metro
    VERSION=$1

    echo "üöÄ Ejecutando pruebas con Cypress usando la versi√≥n de Ghost ${VERSION}..."
    VERSION=$VERSION npm run test --workspace=e2e/misw-4103-cypress

    echo "üßπ Renombrando y moviendo archivos .png, y eliminando directorios vac√≠os..."

    find e2e/misw-4103-cypress/cypress/screenshots/$VERSION -mindepth 2 -type f -name "*.png" -exec bash -c '
      for file; do
        folder_path=$(dirname "$file")
        folder_name=$(basename "$folder_path")
        ext="${file##*.}"
        new_name="${folder_name}.${ext}"
        mv "$file" "e2e/misw-4103-cypress/cypress/screenshots/'"$VERSION"'/$new_name"
      done
    ' bash {} +

    find e2e/misw-4103-cypress/cypress/screenshots/$VERSION -mindepth 1 -type d -empty -delete
}




kraken_run(){
    npm run test --workspace=e2e/misw-4103-kraken
}

########################################################################################## KRAKEN
kraken_install(){
    npm install kraken-node -g
    kraken-node gen
    npm install kraken-node
}

kraken_run(){
    npm run test --workspace=e2e/misw-4103-kraken
}

kraken_reports_clear(){
    sudo rm -r /e2e/misw-4103-kraken/reports/
}
chromium_listen(){
    chromedriver --port=4444
}





########################################################################################## CYPRESS

cypress_install(){
    sudo npm install -g cypress
}

cypress_open(){
    cypress open
}

cypress_run_headed() {
    FOLDER=$1
    FILE=$2

    if [ "$FOLDER" == "all" ] && [ "$FILE" == "all" ]; then
        # Ejecutar todas las pruebas en modo headed
        sudo cypress run --headed
    elif [ "$FOLDER" == "all" ] && [ -n "$FILE" ]; then
        # Ejecutar un archivo espec√≠fico dentro de una carpeta en modo headed
        sudo cypress run --headed --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/$FILE.cy.js"
    elif [ -n "$FOLDER" ] && [ -n "$FILE" ]; then
        # Ejecutar un archivo espec√≠fico en una carpeta espec√≠fica en modo headed
        sudo cypress run --headed --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/$FILE.cy.js"
    else
        # Ejecutar todas las pruebas en una carpeta espec√≠fica en modo headed
        sudo cypress run --headed --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/*.cy.js"
    fi
}

cypress_run_headless() {
    FOLDER=$1
    FILE=$2

    if [ "$FOLDER" == "all" ] && [ "$FILE" == "all" ]; then
        # Ejecutar todas las pruebas en modo headless
        sudo cypress run --headless
    elif [ "$FOLDER" == "all" ] && [ -n "$FILE" ]; then
        # Ejecutar un archivo espec√≠fico dentro de una carpeta en modo headless
        sudo cypress run --headless --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/$FILE.cy.js"
    elif [ -n "$FOLDER" ] && [ -n "$FILE" ]; then
        # Ejecutar un archivo espec√≠fico en una carpeta espec√≠fica en modo headless
        sudo cypress run --headless --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/$FILE.cy.js"
    else
        # Ejecutar todas las pruebas en una carpeta espec√≠fica en modo headless
        sudo cypress run --headless --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/*.cy.js"
    fi
}

agregar_x() {
    #!/bin/bash    
    carpeta="."     
    for archivo in "$carpeta"/*; do
      if [ -f "$archivo" ]; then
        nombre_base=$(basename "$archivo")
        nuevo_nombre="${nombre_base}.x"
        mv "$archivo" "$carpeta/$nuevo_nombre"
      fi
    done
}

saludar(){
    echo "Hola a todos"
}

quitar_x(){
    #!/bin/bash   
    carpeta="."  # Cambia esto por la ruta real    
    for archivo in "$carpeta"/*.x; do
      if [ -f "$archivo" ]; then
        nuevo_nombre="${archivo%.x}"
        mv "$archivo" "$nuevo_nombre"
      fi
    done
}
########################################################################################## OLLAMA
ollama_install(){
  sudo apt-get install zstd
  curl -fsSL https://ollama.com/install.sh | sh
}

ollama_pull () {
  # Cat√°logo curado (popular/√∫til) + descripciones.
  # Puedes ampliar/editar esta lista cuando quieras.

  if ! command -v ollama >/dev/null 2>&1; then
    echo "‚ùå 'ollama' no est√° instalado o no est√° en PATH."
    return 1
  fi

  # Lista de modelos (nombres tal como se usan en `ollama pull`)
  local models=(
    "gemma3:1b"
    "gemma2:2b"
    "gemma2:9b"
    "llama3.2:1b"
    "llama3.2:3b"
    "llama3.2:latest"
    "qwen2.5:7b"
    "qwen2.5:14b"
    "mistral:latest"
    "mixtral:8x7b"
    "phi3:mini"
    "phi3:medium"
    "codellama:7b"
    "starcoder2:7b"
    "deepseek-r1:7b"
    "deepseek-coder:6.7b"
  )

  # Descripciones (para qu√© sirve cada uno)
  # Nota: si alg√∫n nombre cambia en tu versi√≥n de Ollama, simplemente ajustas la key.
  declare -A desc=(
    ["gemma3:1b"]="Muy liviano. Ideal para aprender, hacer pruebas r√°pidas y experimentar prompting."
    ["gemma2:2b"]="Peque√±o y pr√°ctico. Buen equilibrio para tareas generales en m√°quina modesta."
    ["gemma2:9b"]="Mejor calidad que los peque√±os. General y bastante s√≥lido sin irse a tama√±os enormes."
    ["llama3.2:1b"]="Ultraligero. √ötil para experimentos r√°pidos; limitado en profundidad."
    ["llama3.2:3b"]="Peque√±o pero m√°s capaz. Buen modelo general para escritorio modesto."
    ["llama3.2:latest"]="General fuerte (seg√∫n disponibilidad local). Bueno para chat/razonamiento."
    ["qwen2.5:7b"]="Excelente para desarrollo y razonamiento. Muy buen ‚Äútodo terreno‚Äù para programar."
    ["qwen2.5:14b"]="Mejor calidad para c√≥digo/razonamiento. Recomendado si tu m√°quina lo aguanta."
    ["mistral:latest"]="R√°pido y eficiente. Bueno para respuestas cortas/medianas y chat."
    ["mixtral:8x7b"]="Muy buen rendimiento (MoE). Excelente calidad, pero m√°s pesado."
    ["phi3:mini"]="Modelo peque√±o para tareas b√°sicas y pruebas; r√°pido."
    ["phi3:medium"]="M√°s capaz que mini; buen balance para tareas generales."
    ["codellama:7b"]="Orientado a programaci√≥n (Code). √ötil si quieres foco en c√≥digo."
    ["starcoder2:7b"]="Muy bueno para c√≥digo (especialmente completaci√≥n y patrones de programaci√≥n)."
    ["deepseek-r1:7b"]="Fuerte en razonamiento (seg√∫n variante). √ötil para problemas l√≥gicos."
    ["deepseek-coder:6.7b"]="Fuerte para c√≥digo. Buen competidor para tareas de programaci√≥n."
  )

  echo "üåê Cat√°logo de modelos recomendados para descargar con Ollama"
  echo "   (Selecciona uno y lo instalo con 'ollama pull')"
  echo

  for i in "${!models[@]}"; do
    local m="${models[$i]}"
    local d="${desc[$m]:-Modelo popular (sin descripci√≥n en cat√°logo).}"
    printf "  [%d] %-20s ‚Äî %s\n" "$((i+1))" "$m" "$d"
  done

  echo
  read -rp "üëâ Selecciona un modelo para instalar (1-${#models[@]}) o Enter para cancelar: " choice
  if [ -z "${choice:-}" ]; then
    echo "‚ÑπÔ∏è  Cancelado."
    return 0
  fi

  if ! [[ "$choice" =~ ^[0-9]+$ ]] || (( choice < 1 || choice > ${#models[@]} )); then
    echo "‚ùå Selecci√≥n inv√°lida."
    return 1
  fi

  local selected="${models[$((choice-1))]}"
  echo
  echo "‚¨áÔ∏è  Instalando: $selected"
  ollama pull "$selected"
  echo "‚úÖ Instalado: $selected"
}


ollama_modelfile_generate () {
  # Nota: no uso "set -euo pipefail" para que si hay error lo veas y no muera en silencio

  _mf_print_hr() { printf '%*s\n' "${COLUMNS:-80}" '' | tr ' ' '-'; }
  _mf_title() { _mf_print_hr; echo "ü¶ô Ollama Modelfile Generator (sin whiptail)"; _mf_print_hr; }
  _mf_pause() { read -r -p "Enter para continuar..." _; }

  # options: array of "value|description" (name by reference) -> returns value in REPLY
  _mf_menu_vd() {
    local prompt="$1"
    local arr_name="$2"
    local -n _opts="$arr_name"

    echo
    echo "$prompt"
    local i=1
    for opt in "${_opts[@]}"; do
      local v="${opt%%|*}"
      local d="${opt#*|}"
      printf "  %2d) %-8s  %s\n" "$i" "$v" "$d"
      i=$((i+1))
    done

    while true; do
      read -r -p "Selecciona (1-${#_opts[@]}): " ans
      if [[ "$ans" =~ ^[0-9]+$ ]] && (( ans>=1 && ans<=${#_opts[@]} )); then
        local chosen="${_opts[$((ans-1))]}"
        REPLY="${chosen%%|*}"
        return 0
      fi
      echo "‚ùå Opci√≥n inv√°lida."
    done
  }

  # ===== Directories (HOME) =====
  local ROOT_DIR MF_DIR
  ROOT_DIR="$HOME/ollama"
  MF_DIR="$ROOT_DIR/modelfiles"
  mkdir -p "$MF_DIR" || { echo "‚ùå No pude crear $MF_DIR"; return 1; }

  _mf_title
  echo "üìÅ Carpeta destino: $MF_DIR"
  echo "‚ÑπÔ∏è  El Modelfile queda con FROM __BASE_MODEL__ (luego lo reemplazas por el modelo real)."
  _mf_pause

  # ===== Tipo / SYSTEM =====
  local TYPE SYSTEM_TEXT
  local -a TYPE_OPTS=(
    "chat|Conversaci√≥n general y asistencia cotidiana"
    "dev|Desarrollo/arquitectura: decisiones t√©cnicas y buenas pr√°cticas"
    "code|C√≥digo preciso y determinista (menos creatividad, m√°s exactitud)"
    "llm|An√°lisis acad√©mico y estudio de LLMs"
    "reason|Razonamiento estructurado paso a paso"
    "docs|Redacci√≥n t√©cnica/profesional con estructura"
    "promptlab|Experimentaci√≥n y pruebas de prompts"
  )
  _mf_menu_vd "TIPO ‚Üí Define el ‚Äúrol‚Äù del modelo (SYSTEM). Esto es como decirle qui√©n es y c√≥mo debe responder." TYPE_OPTS
  TYPE="$REPLY"

  case "$TYPE" in
    chat) SYSTEM_TEXT=$'Asistente general, claro y conciso.\nResponde en espa√±ol.' ;;
    dev) SYSTEM_TEXT=$'Asistente de desarrollo.\nSoluciones ejecutables, patrones y buenas pr√°cticas.' ;;
    code) SYSTEM_TEXT=$'Asistente de programaci√≥n.\nC√≥digo correcto, minimal y determinista.' ;;
    llm) SYSTEM_TEXT=$'Asistente acad√©mico para estudiar y analizar LLMs.' ;;
    reason) SYSTEM_TEXT=$'Asistente de razonamiento paso a paso y an√°lisis l√≥gico.' ;;
    docs) SYSTEM_TEXT=$'Redactor t√©cnico y acad√©mico, claro y estructurado.' ;;
    promptlab) SYSTEM_TEXT=$'Asistente para experimentar, evaluar y depurar prompts.' ;;
    *) SYSTEM_TEXT=$'Asistente general.' ;;
  esac

  # ===== Par√°metros =====
  local TEMP TOP_P TOP_K NUM_CTX NUM_PRED REP_PEN REP_LAST_N PEN_NL

  # temperature
  local -a TEMP_OPTS=(
    "0.2|Ultra estable: ideal para c√≥digo, reglas, parsing y salidas repetibles"
    "0.35|Equilibrado: buena precisi√≥n sin rigidez (uso general recomendado)"
    "0.6|Exploratorio: mejor para conversaci√≥n y redacci√≥n con variedad"
    "0.8|Creativo: brainstorming/estilo; mayor riesgo de desviarse"
  )
  _mf_menu_vd "temperature ‚Üí Controla QU√â TANTO se ‚Äúarriesga‚Äù el modelo al elegir la siguiente palabra. Bajo = m√°s predecible y exacto. Alto = m√°s variado y creativo." TEMP_OPTS
  TEMP="$REPLY"

  # top_p
  local -a TOP_P_OPTS=(
    "0.7|Muy conservador: recorta fuerte opciones raras"
    "0.8|Conservador: control alto con algo de variedad"
    "0.9|Balanceado: n√∫cleo t√≠pico (recomendado)"
    "0.95|Diverso: m√°s libertad, menos foco"
    "1.0|Sin recorte: deja pasar todo (controla con temperature)"
  )
  _mf_menu_vd "top_p ‚Üí Define el ‚ÄúTAMA√ëO del men√∫‚Äù de opciones por probabilidad. El modelo considera solo las palabras m√°s probables hasta sumar p (ej. 0.9). Bajo = menos rarezas. Alto = m√°s diversidad." TOP_P_OPTS
  TOP_P="$REPLY"

  # top_k
  local -a TOP_K_OPTS=(
    "0|Desactivado: control solo por top_p (suave)"
    "40|Est√°ndar: buen control sin rigidez"
    "50|Equilibrado: m√°s variedad manteniendo precisi√≥n"
    "100|Abierto: permite tokens raros y creativos"
  )
  _mf_menu_vd "top_k ‚Üí Otro l√≠mite al ‚Äúmen√∫‚Äù: en vez de probabilidad, corta por ranking. Solo permite los K tokens m√°s probables. K bajo = m√°s control. K alto = m√°s opciones. 0 = no usar este corte." TOP_K_OPTS
  TOP_K="$REPLY"

  # num_ctx
  local -a NUM_CTX_OPTS=(
    "2048|Contexto corto: r√°pido/ligero"
    "4096|Contexto normal: recomendado para la mayor√≠a de flujos"
    "8192|Contexto largo: documentos extensos (m√°s RAM/VRAM)"
  )
  _mf_menu_vd "num_ctx ‚Üí La ‚ÄúMEMORIA‚Äù m√°xima en una respuesta. Es cu√°ntos tokens caben sumando: SYSTEM + tu prompt + historial + lo que est√°s preguntando. M√°s contexto = recuerda m√°s, pero consume m√°s recursos." NUM_CTX_OPTS
  NUM_CTX="$REPLY"

  # num_predict
  local -a NUM_PRED_OPTS=(
    "256|Salida corta: respuestas puntuales"
    "512|Salida media: balance entre detalle y foco"
    "1024|Salida larga: explicaciones extensas (riesgo de relleno)"
  )
  _mf_menu_vd "num_predict ‚Üí L√çMITE de longitud de la respuesta. Es el m√°ximo de tokens que el modelo puede generar. √ötil para evitar respuestas eternas o para permitir respuestas largas." NUM_PRED_OPTS
  NUM_PRED="$REPLY"

  # repeat_penalty
  local -a REP_PEN_OPTS=(
    "1.0|Sin penalizaci√≥n: puede repetir si se atasca"
    "1.10|Penalizaci√≥n suave: reduce muletillas (recomendado)"
    "1.20|Penalizaci√≥n fuerte: evita loops, menos natural"
  )
  _mf_menu_vd "repeat_penalty ‚Üí ‚ÄúANTI-REPETICI√ìN‚Äù. Cuando el modelo intenta repetir tokens recientes, esta penalizaci√≥n lo empuja a variar. M√°s alto = menos repetici√≥n (pero puede sonar menos natural)." REP_PEN_OPTS
  REP_PEN="$REPLY"

  # repeat_last_n
  local -a REP_LAST_N_OPTS=(
    "64|Ventana corta: impacto m√≠nimo"
    "128|Ventana media: balance ideal"
    "256|Ventana larga: evita repetici√≥n lejana"
  )
  _mf_menu_vd "repeat_last_n ‚Üí Define QU√â TANTO texto hacia atr√°s se revisa para aplicar repeat_penalty. Ventana peque√±a = solo evita repeticiones inmediatas. Ventana grande = evita repetir cosas dichas hace m√°s rato." REP_LAST_N_OPTS
  REP_LAST_N="$REPLY"

  # penalize_newline
  local -a PEN_NL_OPTS=(
    "false|Permite formato rico: markdown, listas y c√≥digo"
    "true|Texto compacto: menos saltos de l√≠nea"
  )
  _mf_menu_vd "penalize_newline ‚Üí Controla la TENDENCIA a usar saltos de l√≠nea. Si lo penalizas, responde m√°s ‚Äúen p√°rrafo‚Äù. Si no, facilita listas, markdown y bloques de c√≥digo." PEN_NL_OPTS
  PEN_NL="$REPLY"

  # ===== Nombre (√∫nico input escrito) =====
  echo
  local NAME
  read -r -p "Nombre del Modelfile (√∫nico campo que se escribe) [my-${TYPE}]: " NAME
  NAME="${NAME:-my-${TYPE}}"
  NAME="$(echo "$NAME" | tr -cd 'a-zA-Z0-9._-')"
  [[ -z "$NAME" ]] && { echo "‚ùå Nombre inv√°lido."; return 1; }

  local FILE="$MF_DIR/Modelfile.${NAME}"
  if [[ -e "$FILE" ]]; then
    echo "‚ö†Ô∏è Ya existe: $FILE"
    read -r -p "¬øSobrescribir? (y/N): " yn
    [[ "${yn,,}" == "y" ]] || { echo "Cancelado."; return 1; }
  fi

  cat > "$FILE" <<EOF
FROM __BASE_MODEL__

SYSTEM """
${SYSTEM_TEXT}
"""

PARAMETER temperature ${TEMP}
PARAMETER top_p ${TOP_P}
PARAMETER top_k ${TOP_K}
PARAMETER num_ctx ${NUM_CTX}
PARAMETER num_predict ${NUM_PRED}
PARAMETER repeat_penalty ${REP_PEN}
PARAMETER repeat_last_n ${REP_LAST_N}
PARAMETER penalize_newline ${PEN_NL}
EOF

  echo
  _mf_print_hr
  echo "‚úÖ Modelfile creado correctamente:"
  echo "   $FILE"
  _mf_print_hr
}

ollama_model_generate () {
  # ---- Config ----
  local MF_DIR="$HOME/ollama/modelfiles"
  local TMP_DIR="${TMPDIR:-/tmp}"
  local BASE_MODEL="" MF_PATH="" NEW_NAME=""
  local -a MODELS=() FILES=()

  _omc_hr() { printf '%*s\n' "${COLUMNS:-80}" '' | tr ' ' '-'; }
  _omc_title() { _omc_hr; echo "ü¶ô Ollama Model Creator (base + Modelfile)"; _omc_hr; }
  _omc_die() { echo "‚ùå $*"; return 1; }

  # Men√∫ gen√©rico: recibe prompt + array name, retorna REPLY=elemento elegido
  _omc_menu() {
    local prompt="$1"
    local arr_name="$2"
    local -n _opts="$arr_name"
    echo
    echo "$prompt"
    local i=1
    for opt in "${_opts[@]}"; do
      printf "  %2d) %s\n" "$i" "$opt"
      i=$((i+1))
    done
    while true; do
      read -r -p "Selecciona (1-${#_opts[@]}): " ans
      if [[ "$ans" =~ ^[0-9]+$ ]] && (( ans>=1 && ans<=${#_opts[@]} )); then
        REPLY="${_opts[$((ans-1))]}"
        return 0
      fi
      echo "‚ùå Opci√≥n inv√°lida."
    done
  }

  # ---- Checks ----
  command -v ollama >/dev/null 2>&1 || _omc_die "No encuentro 'ollama' en PATH."
  [[ -d "$MF_DIR" ]] || _omc_die "No existe la carpeta de Modelfiles: $MF_DIR"

  _omc_title

  # ---- Cargar modelos locales ----
  # `ollama list` imprime cabecera + columnas; tomamos la primera columna (NAME)
  mapfile -t MODELS < <(ollama list 2>/dev/null | awk 'NR>1 && $1!="" {print $1}')
  (( ${#MODELS[@]} > 0 )) || _omc_die "No hay modelos locales. Primero haz: ollama pull <modelo>"

  _omc_menu "Elige el MODELO BASE (ya descargado):" MODELS
  BASE_MODEL="$REPLY"

  # ---- Cargar Modelfiles disponibles ----
  # Mostramos solo el nombre de archivo para el men√∫
  mapfile -t FILES < <(find "$MF_DIR" -maxdepth 1 -type f -name 'Modelfile.*' -printf '%f\n' | sort)
  (( ${#FILES[@]} > 0 )) || _omc_die "No encuentro Modelfiles en $MF_DIR (esperaba Modelfile.*)"

  _omc_menu "Elige el Modelfile (en $MF_DIR):" FILES
  MF_PATH="$MF_DIR/$REPLY"

  # ---- Nombre del modelo final ----
  echo
  read -r -p "Nombre del NUEVO modelo (√∫nico input) [${REPLY#Modelfile.}]: " NEW_NAME
  NEW_NAME="${NEW_NAME:-${REPLY#Modelfile.}}"
  NEW_NAME="$(echo "$NEW_NAME" | tr -cd 'a-zA-Z0-9._:-')"
  [[ -n "$NEW_NAME" ]] || _omc_die "Nombre inv√°lido."

  # Confirmar si ya existe
  if ollama list 2>/dev/null | awk 'NR>1 {print $1}' | grep -Fxq "$NEW_NAME"; then
    echo "‚ö†Ô∏è Ya existe un modelo llamado: $NEW_NAME"
    read -r -p "¬øSobrescribir (recrear) ese modelo? (y/N): " yn
    [[ "${yn,,}" == "y" ]] || _omc_die "Cancelado."
  fi

  # ---- Crear un Modelfile temporal (sin tocar el original) ----
  local TMP_MF="$TMP_DIR/Modelfile.${NEW_NAME}.$$"
  # Reemplaza SOLO si existe el placeholder exacto
  if grep -q '^FROM __BASE_MODEL__' "$MF_PATH"; then
    sed "s|^FROM __BASE_MODEL__\$|FROM ${BASE_MODEL}|" "$MF_PATH" > "$TMP_MF"
  else
    # Si no hay placeholder, lo dejamos como est√° (por si ya tiene FROM real)
    cp "$MF_PATH" "$TMP_MF"
  fi

  echo
  _omc_hr
  echo "üß© Combinando:"
  echo "  Base:     $BASE_MODEL"
  echo "  Modelfile: $MF_PATH"
  echo "  Nuevo:    $NEW_NAME"
  _omc_hr
  echo

  # ---- Crear modelo ----
  if ! ollama create "$NEW_NAME" -f "$TMP_MF"; then
    rm -f "$TMP_MF"
    _omc_die "Fall√≥ ollama create. Revisa que el modelo base exista y el Modelfile sea v√°lido."
  fi

  rm -f "$TMP_MF"

  echo
  _omc_hr
  echo "‚úÖ Modelo creado: $NEW_NAME"
  echo "‚ñ∂Ô∏è  Probar ahora:"
  echo "    ollama run $NEW_NAME"
  _omc_hr

  # Ejecutar opcional
  echo
  read -r -p "¬øQuieres ejecutarlo ahora? (y/N): " runnow
  if [[ "${runnow,,}" == "y" ]]; then
    ollama run "$NEW_NAME"
  fi
}

ollama_assistant () {
  # -----------------------
  # Config base
  # -----------------------
  local PORT="11434"
  local DEFAULT_BASE="http://localhost:${PORT}"
  local MF_DIR="$HOME/ollama/modelfiles"
  local TMP_DIR="${TMPDIR:-/tmp}"

  # Estado "en memoria" del asistente (no persistente salvo que apliques systemd)
  local API_BASE="${OLLAMA_API_BASE:-$DEFAULT_BASE}"
  local CUR_HOST_BIND="127.0.0.1"     # sugerencia para serve (local)
  local CUR_ORIGINS="(sin tocar)"
  local CUR_MAX_LOADED="(default)"
  local CUR_NUM_PARALLEL="(default)"
  local CUR_MAX_QUEUE="(default)"
  local CUR_KEEP_ALIVE="(default)"
  local CUR_NUM_GPU="(default)"

  # -----------------------
  # Utils
  # -----------------------
  _hr() { printf '%*s\n' "${COLUMNS:-90}" '' | tr ' ' '-'; }
  _title() { _hr; echo "ü¶ô Ollama Server Assistant (una sola funci√≥n)"; _hr; }
  _note() { echo "‚ÑπÔ∏è  $*"; }
  _ok() { echo "‚úÖ $*"; }
  _warn() { echo "‚ö†Ô∏è  $*"; }
  _err() { echo "‚ùå $*"; }
  _pause() { read -r -p "Enter para continuar..." _; }

  _need() { command -v "$1" >/dev/null 2>&1 || { _err "Falta '$1' en PATH."; return 1; }; }

  _ip_local() {
    if command -v hostname >/dev/null 2>&1; then
      local ip
      ip="$(hostname -I 2>/dev/null | awk '{print $1}')"
      [[ -n "$ip" ]] && { echo "$ip"; return 0; }
    fi
    ip route get 1.1.1.1 2>/dev/null | awk '/src/ {for(i=1;i<=NF;i++) if($i=="src") print $(i+1)}' | head -n1
  }

  # Men√∫ simple: array de "key|title"
  _menu() {
    local prompt="$1"
    local arr_name="$2"
    local -n opts="$arr_name"
    echo
    echo "$prompt"
    local i=1
    for o in "${opts[@]}"; do
      printf "  %2d) %s\n" "$i" "${o#*|}"
      i=$((i+1))
    done
    while true; do
      read -r -p "Selecciona (1-${#opts[@]}): " ans
      if [[ "$ans" =~ ^[0-9]+$ ]] && (( ans>=1 && ans<=${#opts[@]} )); then
        REPLY="${opts[$((ans-1))]%%|*}"
        return 0
      fi
      _err "Opci√≥n inv√°lida."
    done
  }

  _set_api_base() {
    echo
    _note "API_BASE es la URL donde vive el servidor HTTP de Ollama."
    _note "Ejemplos:"
    echo "  - Local:  http://localhost:${PORT}"
    echo "  - Remoto: http://192.168.1.100:${PORT}"
    echo
    read -r -p "API_BASE actual: ${API_BASE}. Nuevo (Enter para dejar igual): " nb
    if [[ -n "$nb" ]]; then
      API_BASE="$nb"
      export OLLAMA_API_BASE="$API_BASE"
      _ok "OLLAMA_API_BASE actualizado: $OLLAMA_API_BASE"
    else
      _note "Sin cambios."
    fi
  }

  _health() {
    _need curl || return 1
    if curl -sf "$API_BASE/api/tags" >/dev/null; then
      _ok "Ollama responde en $API_BASE"
      return 0
    else
      _err "Ollama NO responde en $API_BASE"
      _note "Si es local, prueba iniciar con: (opci√≥n) Iniciar servidor local/LAN"
      return 1
    fi
  }

  _show_tags() {
    _need curl || return 1
    _note "Esto consulta /api/tags, que devuelve los modelos instalados localmente en el servidor."
    curl -s "$API_BASE/api/tags" || return 1
    echo
  }

  _models_clean() {
    _need curl || return 1
    _note "Listado limpio de modelos (solo nombres) desde /api/tags."
    curl -s "$API_BASE/api/tags" | sed -n 's/.*"name":"\([^"]*\)".*/\1/p' | sort -u
  }

  _serve_local() {
    _need ollama || return 1
    _title
    echo "üß© INICIAR SERVIDOR LOCAL (127.0.0.1:${PORT})"
    _hr
    cat <<EOF
Concepto:
- "ollama serve" levanta el servidor HTTP integrado.
- Por defecto escucha SOLO en localhost (127.0.0.1). Eso significa:
  ‚úÖ Solo accesible desde esta misma m√°quina.
  ‚úÖ M√°s seguro por defecto.
  ‚ùå No lo puede consumir otra m√°quina de tu red.

Qu√© hace esta opci√≥n:
- Ejecuta Ollama con OLLAMA_HOST=127.0.0.1 (escucha solo local).
- Si el puerto ya est√° ocupado, normalmente es porque Ollama YA est√° corriendo
  como servicio (muy com√∫n en Linux).
EOF
    echo
    _pause
    OLLAMA_HOST="127.0.0.1" ollama serve 2>&1 | awk '
      /address already in use/ { print "‚ö†Ô∏è  Puerto ocupado: probablemente Ollama ya est√° corriendo (o algo usa 11434)."; exit 0 }
      { print }
    '
  }

  _serve_lan() {
    _need ollama || return 1
    _title
    echo "üåê INICIAR SERVIDOR EN RED (0.0.0.0:${PORT})"
    _hr
    cat <<EOF
Concepto:
- Poner OLLAMA_HOST=0.0.0.0 hace que Ollama escuche en TODAS las interfaces de red.
- Esto permite:
  ‚úÖ Acceso desde otra m√°quina en tu LAN (ej: tu laptop, un servidor, un contenedor).
  ‚úÖ Integraci√≥n con apps externas (web, notebooks, etc.) desde otra IP.
- Pero tambi√©n implica:
  ‚ö†Ô∏è Riesgo: cualquiera con acceso a tu red podr√≠a pegarle al endpoint.
  ‚úÖ Recomendaci√≥n: abrir el puerto SOLO a tu red local (UFW) o usar VPN / reverse proxy con auth.

Tip:
- Despu√©s de levantarlo, prueba desde otra m√°quina:
  curl http://<TU_IP>:11434/api/tags
EOF
    echo
    _pause
    _warn "Exponiendo a red. Considera firewall."
    OLLAMA_HOST="0.0.0.0" ollama serve 2>&1 | awk '
      /address already in use/ { print "‚ö†Ô∏è  Puerto ocupado: probablemente Ollama ya est√° corriendo (o algo usa 11434)."; exit 0 }
      { print }
    '
  }

  _test_from_other_machine_instructions() {
    local ip; ip="$(_ip_local)"
    _title
    echo "üß™ PROBAR ACCESO DESDE OTRA M√ÅQUINA"
    _hr
    cat <<EOF
Paso a paso (LAN):
1) Aseg√∫rate de que Ollama est√© escuchando en 0.0.0.0 (opci√≥n 'Iniciar servidor en red').
2) Ubica la IP local de ESTA m√°quina (servidor):
   - Detectada: ${ip:-"(no detectada)"}
3) Desde la OTRA m√°quina, ejecuta:
   curl http://${ip:-<TU_IP>}:${PORT}/api/tags

Interpretaci√≥n:
- Si responde con JSON y lista de modelos -> ‚úÖ OK
- Si no responde -> revisa:
  - firewall/ufw
  - que realmente est√© en 0.0.0.0
  - que ambas m√°quinas est√©n en la misma red
EOF
    _pause
  }

  _generate_http() {
    _need curl || return 1
    _title
    echo "‚úçÔ∏è GENERAR TEXTO V√çA HTTP (/api/generate)"
    _hr
    cat <<EOF
Concepto:
- /api/generate es una forma de usar Ollama como "microservicio" desde scripts.
- En vez de 'ollama run', t√∫ mandas un JSON por HTTP con:
  - model: nombre del modelo (ej. llama3.1:8b o tu modelo personalizado)
  - prompt: tu pregunta
  - stream: false (para que devuelva todo de una)

√ötil para:
- Automatizaciones (res√∫menes, templates, transformaciones)
- Integraciones (web apps, pipelines, cron jobs)
EOF
    echo
    _pause

    # Elegir modelo desde API
    local model
    model="$(_models_clean | head -n 1)"
    echo
    _note "Modelo sugerido (primer modelo del servidor): ${model:-"(no encontrado)"}"
    read -r -p "Modelo a usar (Enter para '${model}'): " m2
    model="${m2:-$model}"
    [[ -n "$model" ]] || { _err "No hay modelo. Revisa /api/tags."; _pause; return 1; }

    echo
    read -r -p "Prompt: " prompt
    [[ -n "$prompt" ]] || { _err "Prompt vac√≠o."; _pause; return 1; }

    local prompt_json="${prompt//\\/\\\\}"
    prompt_json="${prompt_json//\"/\\\"}"

    local payload
    payload="$(cat <<EOF
{
  "model": "$model",
  "prompt": "$prompt_json",
  "stream": false
}
EOF
)"
    echo
    _note "Enviando solicitud a $API_BASE/api/generate ..."
    local out
    out="$(curl -s "$API_BASE/api/generate" -d "$payload")" || { _err "Fall√≥ curl"; _pause; return 1; }
    echo
    _hr
    echo "Respuesta (solo texto):"
    _hr
    echo "$out" | sed -n 's/.*"response":"\([^"]*\)".*/\1/p' | sed 's/\\n/\n/g; s/\\"/"/g; s/\\\\/\\/g'
    echo
    _pause
  }

  _systemd_apply_dropin() {
    _need systemctl || return 1
    _title
    echo "üß© SYSTEMD DROP-IN (Linux) ‚Äî Configuraci√≥n persistente"
    _hr
    cat <<EOF
Concepto:
- En Linux, Ollama frecuentemente corre como servicio (ollama.service).
- Si quieres que SIEMPRE arranque con par√°metros de servidor (ej. escuchar en 0.0.0.0),
  se recomienda un "drop-in" en systemd.
- Un drop-in es un archivo adicional que modifica variables sin editar el servicio original.

Qu√© variables tocar (las del texto que compartiste):
- OLLAMA_HOST=0.0.0.0        -> escuchar en todas las interfaces (LAN)
- OLLAMA_ORIGINS=*           -> permite CORS desde cualquier origen (√∫til web; en prod restringir)
- OLLAMA_MAX_LOADED_MODELS=1 -> cu√°ntos modelos mantiene en memoria al mismo tiempo
- OLLAMA_NUM_PARALLEL=1      -> peticiones simult√°neas procesadas
- OLLAMA_MAX_QUEUE=512       -> tama√±o de la cola de espera
- OLLAMA_KEEP_ALIVE=600      -> segundos que el modelo se mantiene cargado tras una petici√≥n
- OLLAMA_NUM_GPU=1           -> n√∫mero de GPUs permitidas

IMPORTANTE:
- Exponer 0.0.0.0 sin firewall es riesgoso.
- Para LAN, lo ideal: firewall UFW permitiendo solo tu rango (ej. 192.168.0.0/16).
EOF
    echo
    _pause

    read -r -p "¬øQuieres crear/aplicar el drop-in recomendado (requiere sudo)? (y/N): " yn
    [[ "${yn,,}" == "y" ]] || { _note "Cancelado."; _pause; return 0; }

    local dropin_dir="/etc/systemd/system/ollama.service.d"
    local dropin_file="$dropin_dir/10-ollama-lan.conf"

    sudo mkdir -p "$dropin_dir" || { _err "No pude crear $dropin_dir"; _pause; return 1; }

    sudo tee "$dropin_file" >/dev/null <<'EOF'
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_ORIGINS=*"
Environment="OLLAMA_MAX_LOADED_MODELS=1"
Environment="OLLAMA_NUM_PARALLEL=1"
Environment="OLLAMA_MAX_QUEUE=512"
Environment="OLLAMA_KEEP_ALIVE=600"
Environment="OLLAMA_NUM_GPU=1"
EOF

    _ok "Drop-in creado: $dropin_file"
    _note "Reiniciando servicio para aplicar cambios..."
    sudo systemctl daemon-reload
    sudo systemctl restart ollama.service
    sudo systemctl status ollama.service --no-pager -l | sed -n '1,14p'
    _pause
  }

  _systemd_edit() {
    _need systemctl || return 1
    _title
    echo "üìù EDITAR SYSTEMD (systemctl edit ollama.service)"
    _hr
    cat <<EOF
Esto abre el editor de systemd para que puedas crear un drop-in manualmente.

Tip:
- Pega el bloque bajo [Service] justo despu√©s del comentario:
  '### Anything between here and the comment below will become the contents of the drop-in file.'

Ejemplo (LAN + CORS + l√≠mites):
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_ORIGINS=*"
Environment="OLLAMA_MAX_LOADED_MODELS=1"
Environment="OLLAMA_NUM_PARALLEL=1"
Environment="OLLAMA_MAX_QUEUE=512"
Environment="OLLAMA_KEEP_ALIVE=600"
Environment="OLLAMA_NUM_GPU=1"

Luego:
  sudo systemctl restart ollama.service
EOF
    _pause
    sudo systemctl edit ollama.service
    _pause
  }

  _ufw_allow_lan() {
    _need ufw || return 1
    _title
    echo "üß± FIREWALL UFW ‚Äî Abrir 11434 SOLO para LAN"
    _hr
    cat <<EOF
Concepto (muy importante):
- Si expones Ollama con OLLAMA_HOST=0.0.0.0, el puerto 11434 queda accesible en red.
- Lo seguro es permitir SOLO tu red local (LAN) y bloquear el resto.

Ejemplos de rangos t√≠picos:
- 192.168.0.0/16
- 10.0.0.0/8
- 172.16.0.0/12

Esta opci√≥n crea una regla:
  ufw allow from <CIDR> to any port 11434 proto tcp
EOF
    echo
    read -r -p "Ingresa CIDR permitido (ej 192.168.0.0/16): " cidr
    [[ -n "$cidr" ]] || { _err "CIDR vac√≠o."; _pause; return 1; }
    sudo ufw allow from "$cidr" to any port "$PORT" proto tcp
    _ok "Regla aplicada. Verifica con: sudo ufw status numbered"
    _pause
  }

  _ufw_deny_port() {
    _need ufw || return 1
    _title
    echo "üß± FIREWALL UFW ‚Äî Denegar 11434 (global)"
    _hr
    cat <<EOF
Concepto:
- Si abriste el puerto por accidente o quieres cerrarlo, puedes denegar 11434/tcp.
- Ojo: si tienes reglas allow espec√≠ficas, UFW aplica por orden. Esto es una acci√≥n ‚Äúfuerte‚Äù.

Comando:
  sudo ufw deny 11434/tcp
EOF
    _pause
    read -r -p "¬øAplicar deny global a 11434/tcp? (y/N): " yn
    [[ "${yn,,}" == "y" ]] || { _note "Cancelado."; _pause; return 0; }
    sudo ufw deny "$PORT"/tcp
    _ok "Puerto denegado. Verifica con: sudo ufw status numbered"
    _pause
  }

  _show_workspace_info() {
    _title
    echo "üìÅ WORKSPACE: Modelfiles y conceptos"
    _hr
    cat <<EOF
Tu carpeta de trabajo (workspace) para Modelfiles:
  ${MF_DIR}

Ah√≠ guardas:
- Modelfiles (personalizaciones / recetas)
- scripts de Bash
- todo lo que versionas en Git

Ollama guarda internamente modelos y metadata en:
  ~/.ollama
(esa carpeta no se edita manualmente)

Consejo pr√°ctico:
- Versiona ~/ollama/modelfiles en Git.
- En otra m√°quina, solo necesitas:
    ollama pull <modelo_base>
    ollama create <nuevo> -f <Modelfile>
EOF
    echo
    if [[ -d "$MF_DIR" ]]; then
      _note "Modelfiles detectados:"
      find "$MF_DIR" -maxdepth 1 -type f -name 'Modelfile.*' -printf '  - %f\n' | sort
    else
      _warn "No existe $MF_DIR (cr√©ala o genera Modelfiles primero)."
    fi
    _pause
  }

  _show_env_cheatsheet() {
    _title
    echo "üßæ VARIABLES DE ENTORNO (cheat sheet) ‚Äî qu√© son y para qu√© sirven"
    _hr
    cat <<'EOF'
Estas variables se usan para configurar el servidor HTTP de Ollama, especialmente cuando lo expones en red
o quieres controlar consumo de recursos.

1) OLLAMA_HOST
   - Qu√© controla: en qu√© IP/Interfaz escucha el servidor.
   - Ejemplos:
     * 127.0.0.1  -> solo local (seguro por defecto)
     * 0.0.0.0    -> todas las interfaces (LAN/containers) ‚ö†Ô∏è requiere firewall
   - Cu√°ndo usar 0.0.0.0:
     * cuando quieras consumir Ollama desde otra m√°quina o contenedor

2) OLLAMA_ORIGINS
   - Qu√© controla: desde qu√© "origin" se aceptan solicitudes (CORS) para apps web.
   - Valor:
     * * -> acepta cualquier origen (f√°cil para pruebas, menos seguro)
   - Recomendaci√≥n:
     * en producci√≥n, restringir al dominio exacto de tu app web

3) OLLAMA_MAX_LOADED_MODELS
   - Qu√© controla: cu√°ntos modelos puede mantener cargados al mismo tiempo en RAM/VRAM.
   - Idea:
     * si tienes poca memoria, pon 1 para evitar que se carguen varios y reviente la RAM
   - Trade-off:
     * m√°s bajo -> menos memoria, pero puede recargar modelos m√°s seguido

4) OLLAMA_NUM_PARALLEL
   - Qu√© controla: cu√°ntas solicitudes puede procesar en paralelo (concurrencia real).
   - Trade-off:
     * m√°s alto -> m√°s throughput, pero m√°s presi√≥n de CPU/GPU y memoria

5) OLLAMA_MAX_QUEUE
   - Qu√© controla: cu√°ntas solicitudes se pueden encolar esperando.
   - √ötil:
     * cuando tienes clientes m√∫ltiples y prefieres cola en vez de fallar r√°pido
   - Riesgo:
     * cola demasiado grande -> latencias largas, usuarios ‚Äúesperando‚Äù mucho

6) OLLAMA_KEEP_ALIVE
   - Qu√© controla: cu√°nto tiempo (segundos) el modelo permanece cargado tras terminar una petici√≥n.
   - Ejemplo:
     * 600 -> 10 minutos ‚Äúcaliente‚Äù
   - Trade-off:
     * alto -> respuestas futuras m√°s r√°pidas
     * bajo -> menos memoria retenida

7) OLLAMA_NUM_GPU
   - Qu√© controla: cu√°ntas GPUs puede usar el servidor.
   - Caso t√≠pico:
     * 1 -> una sola GPU disponible
   - Nota:
     * si no tienes GPU, el modelo correr√° en CPU (m√°s lento)
EOF
    _pause
  }

  # -----------------------
  # Men√∫ principal
  # -----------------------
  while true; do
    _title
    echo "API_BASE actual: $API_BASE"
    echo "Workspace Modelfiles: $MF_DIR"
    _hr
    echo "¬øQu√© quieres hacer?"
    local -a MAIN=(
      "health|‚úÖ Verificar servidor (health check) + tips si falla"
      "tags|üì¶ Ver modelos instalados (GET /api/tags) ‚Äî JSON completo"
      "models|üìÉ Listar modelos (limpio) ‚Äî nombres desde /api/tags"
      "gen|‚úçÔ∏è Generar texto por HTTP (POST /api/generate) ‚Äî sin usar 'ollama run'"
      "setbase|üîß Cambiar API_BASE (apuntar a local o remoto)"
      "serve_local|üñ•Ô∏è Iniciar servidor local (127.0.0.1) ‚Äî seguro por defecto"
      "serve_lan|üåê Iniciar servidor en red (0.0.0.0) ‚Äî accesible desde LAN ‚ö†Ô∏è"
      "test_lan|üß™ Gu√≠a para probar acceso desde otra m√°quina (curl a tu IP)"
      "env_help|üßæ Explicaci√≥n generosa de variables (OLLAMA_HOST, ORIGINS, etc.)"
      "systemd_quick|üß© Aplicar drop-in systemd recomendado (LAN + l√≠mites) (Linux)"
      "systemd_edit|üìù Abrir editor systemd (systemctl edit ollama.service) (Linux)"
      "ufw_allow|üß± UFW: permitir 11434 SOLO para tu LAN (CIDR)"
      "ufw_deny|üß± UFW: denegar 11434 global (cerrar puerto)"
      "workspace|üìÅ Ver info de workspace (~/ollama/modelfiles) + listado"
      "exit|Salir"
    )

    _menu "Men√∫ principal:" MAIN
    case "$REPLY" in
      health) _health; _pause ;;
      tags) _show_tags; _pause ;;
      models) _models_clean; echo; _pause ;;
      gen) _generate_http ;;
      setbase) _set_api_base; _pause ;;
      serve_local) _serve_local ;;
      serve_lan) _serve_lan ;;
      test_lan) _test_from_other_machine_instructions ;;
      env_help) _show_env_cheatsheet ;;
      systemd_quick) _systemd_apply_dropin ;;
      systemd_edit) _systemd_edit ;;
      ufw_allow) _ufw_allow_lan ;;
      ufw_deny) _ufw_deny_port ;;
      workspace) _show_workspace_info ;;
      exit) _ok "Listo."; return 0 ;;
      *) _err "Opci√≥n desconocida."; _pause ;;
    esac
  done
}


arduino_install() {

  echo "========================================="
  echo " ü§ñ Arduino + VSCode + IA Setup Assistant"
  echo "========================================="

  # Detect OS
  OS="$(uname -s)"

  echo "üñ•Ô∏è Sistema detectado: $OS"

  # 1. Instalar Arduino CLI
  if ! command -v arduino-cli &> /dev/null; then
    echo "üì¶ Instalando Arduino CLI..."

    if [[ "$OS" == "Linux" ]]; then
      curl -fsSL https://raw.githubusercontent.com/arduino/arduino-cli/master/install.sh | sh
      sudo mv bin/arduino-cli /usr/local/bin/

    elif [[ "$OS" == "Darwin" ]]; then
      brew install arduino-cli

    else
      echo "‚ö†Ô∏è OS no soportado autom√°ticamente."
      echo "Instala Arduino CLI manualmente."
      return 1
    fi

  else
    echo "‚úÖ Arduino CLI ya instalado."
  fi


  # 2. Inicializar config
  echo "‚öôÔ∏è Inicializando configuraci√≥n..."

  if [ ! -f "$HOME/.arduino15/arduino-cli.yaml" ]; then
    arduino-cli config init
  else
    echo "‚úÖ Configuraci√≥n ya existe."
  fi


  # 3. Update index
  echo "üîÑ Actualizando √≠ndice..."
  arduino-cli core update-index


  # 4. Men√∫ placas
  echo ""
  echo "üìü Selecciona tu placa:"
  echo "1) Arduino UNO / Nano"
  echo "2) ESP32"
  echo "3) ESP8266 / NodeMCU"
  echo ""

  read -p "üëâ Opci√≥n: " board


  case $board in

    1)
      echo "üì• Instalando AVR Core..."
      arduino-cli core install arduino:avr
      FQBN="arduino:avr:uno"
      ;;

    2)
      echo "üì• Instalando ESP32 Core..."

      arduino-cli config set board_manager.additional_urls \
      https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json

      arduino-cli core update-index
      arduino-cli core install esp32:esp32

      FQBN="esp32:esp32:esp32"
      ;;

    3)
      echo "üì• Instalando ESP8266 Core..."

      arduino-cli config set board_manager.additional_urls \
      https://arduino.esp8266.com/stable/package_esp8266com_index.json

      arduino-cli core update-index
      arduino-cli core install esp8266:esp8266

      FQBN="esp8266:esp8266:nodemcuv2"
      ;;

    *)
      echo "‚ùå Opci√≥n inv√°lida"
      return 1
      ;;
  esac


  # 5. Detectar puerto
  echo ""
  echo "üîå Buscando placa conectada..."

  arduino-cli board list


  echo ""
  echo "========================================="
  echo " ‚úÖ Instalaci√≥n completada"
  echo "========================================="
  echo ""
  echo "üìå FQBN configurado:"
  echo "   $FQBN"
  echo ""
  echo "üëâ Para compilar:"
  echo "   arduino-cli compile --fqbn $FQBN ."
  echo ""
  echo "üëâ Para subir:"
  echo "   arduino-cli upload -p COMX --fqbn $FQBN ."
  echo ""
  echo "üëâ Para monitor:"
  echo "   arduino-cli monitor -p COMX -c baudrate=115200"
  echo ""
  echo "ü§ñ Ya puedes usar Codex como copiloto."
  echo "========================================="
}







alias venv_iniciar='python3 -m venv .venv'
alias venv_activar='source .venv/bin/activate'
alias venv_desactivar='deactivate'

alias bitnami_reiniciar='sudo /opt/bitnami/ctlscript.sh restart'
alias bitnami_bncert='sudo /opt/bitnami/bncert-tool'
alias bitnami_phpini='sudo nano /opt/bitnami/php/etc/php.ini'
alias errorlog='cat  /opt/bitnami/apache2/logs/error_log'
alias clear-errorlog='sudo truncate -s0  /opt/bitnami/apache2/logs/error_log'

alias bashrc='. ~/.bashrc'

