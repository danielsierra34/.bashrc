alias iadnode_connect='ssh -i iadnode.pem bitnami@34.148.204.101'

#UPa
#sudo 7z x reports.rar -o/opt/bitnami/apache2/htdocs/kraken
#sudo apt install p7zip-full

fastpush() {
  # Si no se pasa mensaje, error y salir
  if [ -z "$1" ]; then
    echo "‚ùå  Debes pasar un mensaje de commit."
    echo "üëâ  Uso: fastpush \"mensaje del commit\""
    return 1
  fi

  # Guarda el mensaje completo (por si contiene espacios)
  local msg="$*"

  echo "üì¶ Agregando archivos..."
  git add .

  echo "üìù Commit con mensaje: \"$msg\""
  git commit -m "$msg" || {
    echo "‚ö†Ô∏è  No hay cambios para commitear."
    return 0
  }

  echo "üöÄ Haciendo push..."
  git push

  echo "‚úÖ  Fastpush completado."
}

linux_version() {
    cat /etc/os-release
}

nano_install(){
    apt update && apt install nano -y
}

ssh_zip() {
    if [ -z "$1" ]; then
        echo "Usage: ssh_zip <foldername>"
        return 1
    fi
    sudo tar -czvf "$1".tgz "$1"/
}

python_serve(){
    python -m http.server 8000
}




flask_run() {
    clear
    flask run
}

flask_restart(){
    clear    
    sudo rm -f ../instance/*.sqlite ../instance/*.db
    flask run
}

bashrc_refresh(){
    cd ~/bashrc
    git pull
    . ~/.bashrc    
    cd -
}

test_all(){
    python -m unittest discover
}

watchdog(){
    watchmedo shell-command --patterns="*.py" --recursive command='python -m unittest discover -s tests -v' .
}

watchdog_always(){
    nohup watchmedo shell-command --patterns="*.py" --recursive --command='python -m unittest discover -s tests -v' . &
}

port_check() {
    sudo lsof -i :"$1"
}

port_kill() {
    sudo kill -9 "$1"
}

ssh_iniciar() {
    eval "$(ssh-agent -s)"
}

ssh_generar() {
  if [ -z "$1" ]; then
    echo "‚ùå Error: Debes proporcionar un nombre para la clave."
    return 1
  fi

  # Definir el nombre del archivo de la clave
  local nombre_clave="$1"
  
  echo "üîë Iniciando la generaci√≥n de la clave SSH sin contrase√±a..."

  # Mensaje sobre los par√°metros recibidos
  echo "üìù Nombre de la clave: $nombre_clave"
  echo "üîí La clave no tendr√° contrase√±a."

  # Generar la clave SSH ED25519 sin passphrase
  echo "‚öôÔ∏è Generando clave SSH con el algoritmo ED25519..."
  ssh-keygen -t ed25519 -C "$nombre_clave" -f "$HOME/.ssh/$nombre_clave" -N ""

  # Verificar si la clave p√∫blica fue generada
  local pub_key="$HOME/.ssh/${nombre_clave}.pub"
  if [ -f "$pub_key" ]; then
    echo "‚úÖ Clave SSH generada con √©xito para '$nombre_clave'."

    # Mostrar contenido de la clave p√∫blica
    echo "üìú Contenido de la clave p√∫blica generada:"
    cat "$pub_key"

    echo "üéâ ¬°La clave p√∫blica ha sido mostrada exitosamente!"
  else
    echo "‚ùå Error: No se pudo generar la clave p√∫blica. Revisa los errores anteriores."
    return 1
  fi
}

ssh_activar() {
    
    if [ -z "$1" ]; then
        echo "Usage: ssh_activar <key_filename>"
        return 1
    fi
    eval "$(ssh-agent -s)"
    ssh-add ~/.ssh/"$1"
}

tree_list(){
    tree -I 'node_modules|venv|.git|__pycache__|dist|build|.pytest_cache|.vscode|.idea|coverage' -a
}

tree_install(){
    sudo apt install tree -y
}
########################################################################################## PYTHON
pyenv_install() {
    echo "üîß Actualizando paquetes..."
    sudo apt update -y

    echo "üì¶ Instalando dependencias..."
    sudo apt install -y make build-essential libssl-dev zlib1g-dev \
        libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm \
        libncurses5-dev libncursesw5-dev xz-utils tk-dev \
        libffi-dev liblzma-dev git

    echo "‚¨áÔ∏è Instalando pyenv..."
    curl https://pyenv.run | bash

    echo "‚öôÔ∏è Configurando variables en ~/.bashrc..."
    if ! grep -q 'pyenv init' ~/.bashrc; then
        cat <<'EOF' >> ~/.bashrc

# >>> pyenv configuration >>>
export PATH="$HOME/.pyenv/bin:$PATH"
eval "$(pyenv init --path)"
eval "$(pyenv init -)"
eval "$(pyenv virtualenv-init -)"
# <<< pyenv configuration <<<
EOF
    fi

    echo "üîÑ Recargando configuraci√≥n..."
    source ~/.bashrc

    echo "‚úÖ Instalaci√≥n completada. Versi√≥n de pyenv:"
    pyenv --version
}

pyenv_local() {
  local version=$1
  if [ -z "$version" ]; then
    echo "‚ùå Debes pasar una versi√≥n. Ejemplo: set_pyenv_local 3.11.9"
    return 1
  fi

  # Verificar si ya est√° instalada
  if ! pyenv versions --bare | grep -q "^${version}\$"; then
    echo "üîç Python $version no est√° instalado. Instalando..."
    pyenv install "$version"
  else
    echo "‚úÖ Python $version ya est√° instalado."
  fi

  # Configurar como local
  pyenv local "$version"
  echo "üìå Se configur√≥ Python $version como versi√≥n local en $(pwd)"
}

pyenv_version() {
  if ! command -v pyenv >/dev/null 2>&1; then
    echo "‚ùå pyenv no est√° instalado o no est√° en el PATH."
    return 1
  fi

  echo "üêç Versi√≥n activa de Python con pyenv:"
  pyenv exec python -V
}

pyenv_venv() {
    if [ -z "$1" ]; then
        echo "‚ùå Debes pasar el nombre del environment como par√°metro"
        echo "üëâ Ejemplo: make_env myproject"
        return 1
    fi

    ENV_NAME="$1"
    ENV_DIR=".$ENV_NAME"

    echo "üöÄ Creando environment en $ENV_DIR ..."
    pyenv exec python -m venv "$ENV_DIR"

    echo "‚úÖ Environment creado: $ENV_DIR"
    echo "üëâ Act√≠valo con: source $ENV_DIR/bin/activate"
}

pyenv_activate_venv() {
    if [ -z "$1" ]; then
        echo "‚ùå Debes pasar el nombre del environment como par√°metro"
        echo "üëâ Ejemplo: activate_env venv"
        return 1
    fi

    ENV_NAME="$1"
    ENV_DIR=".$ENV_NAME"

    if [ ! -d "$ENV_DIR" ]; then
        echo "‚ùå El environment $ENV_DIR no existe."
        echo "üëâ Primero cr√©alo con: make_env $ENV_NAME"
        return 1
    fi

    echo "‚ö° Activando environment: $ENV_DIR ..."
    source "$ENV_DIR/bin/activate"
}

pyenv_gitignore() {
  local file=".gitignore"

  cat > "$file" <<EOF
# ========================
# Archivos Python compilados
# ========================
*.pyc
*.pyo
*.pyd
__pycache__/

# ========================
# Entornos virtuales
# ========================
.env
.venv/
env/
venv/
ENV/

# ========================
# Bases de datos
# ========================
*.db
*.sqlite3

# ========================
# Archivos de pruebas
# ========================
.coverage
coverage.xml
*.cover
*.py,cover
.pytest_cache/
htmlcov/
.tox/
.nox/

# ========================
# Distribuci√≥n / empaquetado
# ========================
build/
dist/
*.egg-info/
.eggs/

# ========================
# Logs
# ========================
*.log

# ========================
# IDEs / Editores
# ========================
.vscode/
.idea/

# ========================
# Archivos del sistema
# ========================
.DS_Store
Thumbs.db

# ========================
# Im√°genes y binarios
# ========================
*.png
*.jpg
*.jpeg
*.gif
*.svg
*.ico

# ========================
# Otros
# ========================
*.bak
*.tmp
EOF

  echo "‚úÖ Archivo $file sobrescrito en $(pwd)"
}

pyenv_create_settings() {
    CONFIG_DIR=".vscode"
    CONFIG_FILE="$CONFIG_DIR/settings.json"

    # Crear carpeta .vscode si no existe
    mkdir -p "$CONFIG_DIR"

    # Crear archivo settings.json con la configuraci√≥n
    cat > "$CONFIG_FILE" <<EOL
{
    "[python]": {
        "editor.codeActionsOnSave": {
            "source.organizeImports": "explicit",
            "source.fixAll": "explicit"
        }
    },
    "editor.formatOnSave": true,
    "editor.defaultFormatter": "charliermarsh.ruff"
}
EOL

    echo "‚úÖ Archivo de configuraci√≥n creado en $CONFIG_FILE"
}

pycache_delete(){
    find . -type d -name "__pycache__" -exec rm -r {} +
}

pytestcache_delete(){
    find . -type d -name ".pytest_cache" -exec rm -r {} +
}

########################################################################################## UVICORN
uvicorn_run() {
  PACKAGE=${1:-"storeapi"}       # Nombre del paquete (impl√≠citamente usa main:app)
  HOST=${2:-"127.0.0.1"}         # Host por defecto
  PORT=${3:-8000}                # Puerto por defecto
  WORKERS=${4:-1}                # N√∫mero de workers por defecto
  RELOAD=${5:-"--reload"}        # Por defecto en modo desarrollo

  APP="$PACKAGE.main:app"        # Construcci√≥n impl√≠cita

  echo "üöÄ Iniciando Uvicorn con APP=$APP en $HOST:$PORT con $WORKERS worker(s) $RELOAD"
  uvicorn $APP --host $HOST --port $PORT --workers $WORKERS $RELOAD
}

########################################################################################## FASTAPI

fastapi_install() {
    if [ -z "$VIRTUAL_ENV" ]; then
        echo "‚ö†Ô∏è No hay ning√∫n entorno virtual activado."
        echo "üëâ Primero activa tu venv con: source .venv/bin/activate"
        return 1
    fi

    echo "üì¶ Instalando FastAPI y Uvicorn en $VIRTUAL_ENV..."
    pip install --upgrade pip
    pip install fastapi uvicorn

    echo "üéâ FastAPI y Uvicorn instalados correctamente"
}

########################################################################################## REQUIREMENTS

requirements_install() {
    REQ_FILE=${1:-"requirements.txt"}  # Usa requirements.txt por defecto si no se pasa nada

    echo "üì¶ Instalando dependencias desde $REQ_FILE..."
    pip install --upgrade pip
    pip install -r "$REQ_FILE"
    echo "‚úÖ Dependencias instaladas desde $REQ_FILE."
}

requirements_generate() {
    echo "üìÑ Generando requirements.txt..."
    pip freeze > requirements.txt
    echo "‚úÖ requirements.txt actualizado."
}


########################################################################################## NPM
npm_list(){
    npm list -g --depth=0
}
npm_install(){
    if [ -z "$1" ]; then
        echo "Usage: npm_install <packageName>"
        return 1
    fi
    sudo npm install -g "$1"
}
npm_uninstall(){
    if [ -z "$1" ]; then
        echo "Usage: npm_uninstall <packageName>"
        return 1
    fi
    sudo npm uninstall -g "$1"
}
npx_list(){
    npm list --depth=0
}
npx_install(){
    if [ -z "$1" ]; then
        echo "Usage: npx_install <packageName>"
        return 1
    fi
    npm install "$1"
}
npx_uninstall(){
    if [ -z "$1" ]; then
        echo "Usage: npx_uninstall <packageName>"
        return 1
    fi
    npm uninstall "$1"
}

########################################################################################## GIT
git_email() {
    if [ -z "$1" ]; then
        echo "Uso: git_set_email \"correo@example.com\""
        return 1
    fi
    git config --global user.email "$1"
    echo "Correo de Git configurado como: $1"
}

git_name() {
    if [ -z "$1" ]; then
        echo "Uso: git_set_name \"Tu Nombre\""
        return 1
    fi
    git config --global user.name "$1"
    echo "Nombre de Git configurado como: $1"
}



########################################################################################## DOCKER

docker_restart(){
  docker compose build --no-cache && docker compose up
}

docker_networks(){
    sudo docker network ls

}

docker_networks_create(){
    if [ -z "$1" ]; then
        echo "Usage: cdocker_networks_create <network_name>"
        return 1
    fi

    NETWORK_NAME="$1"

    if sudo docker network inspect "$NETWORK_NAME" >/dev/null 2>&1; then
        echo "Network '$NETWORK_NAME' already exists."
    else
        sudo docker network create "$NETWORK_NAME"
        echo "Network '$NETWORK_NAME' created successfully."
    fi
}

docker_networks_delete(){
        if [ -z "$1" ]; then
        echo "Usage: docker_networks_delete <network_name | all>"
        return 1
    fi

    NETWORK_NAME="$1"

    if [ "$NETWORK_NAME" == "all" ]; then
        echo "Deleting all user-defined Docker networks..."
        # List all user-defined networks (excluding 'bridge', 'host', 'none') and delete them
        for net in $(sudo docker network ls --format "{{.Name}}" --filter "driver=bridge"); do
            if [[ "$net" != "bridge" && "$net" != "host" && "$net" != "none" ]]; then
                echo "Deleting network: $net"
                sudo docker network rm "$net"
            fi
        done
        echo "All user-defined networks deleted successfully."
    else
        # Check if the specific network exists
        if sudo docker network inspect "$NETWORK_NAME" >/dev/null 2>&1; then
            # Check if any containers are connected to the network
            if [ "$(sudo docker network inspect --format='{{range .Containers}}{{.Name}} {{end}}' "$NETWORK_NAME")" ]; then
                echo "Error: Network '$NETWORK_NAME' has active containers. Remove them first."
                return 1
            fi

            # Remove the network
            sudo docker network rm "$NETWORK_NAME"
            echo "Network '$NETWORK_NAME' deleted successfully."
        else
            echo "Network '$NETWORK_NAME' does not exist."
        fi
    fi
}

docker_c(){
    sudo docker ps -a
}

docker_c_run() {
    if [ -z "$1" ] || [ -z "$2" ] || [ -z "$3" ] || [ -z "$4" ]; then
        echo "Usage: docker_c_run <originPort> <destinationPort> <image_name> <container_name>"
        return 1
    fi
    sudo docker run -d -p "$2:$1" --name "$4" "$3"
}

docker_c_run_in_network() {
    if [ -z "$1" ] || [ -z "$2" ] || [ -z "$3" ] || [ -z "$4" ] || [ -z "$5" ]; then
        echo "Usage: docker_run <originPort> <destinationPort> <image_name> <container_name> <network>"
        return 1
    fi

    CUSTOM_URL="$5"  # Set the custom URL to the 5th parameter (network name)
    
    sudo docker run --network "$5" -p "$2:$1" --name "$4" -e CUSTOM_URL="$CUSTOM_URL" "$3"
}


docker_c_run_always() {
    if [ -z "$1" ] || [ -z "$2" ] || [ -z "$3" ] || [ -z "$4" ]; then
        echo "Usage: docker_run <originPort> <destinationPort> <image_name> <container_name>"
        return 1
    fi
    sudo docker run -dp "$2":"$1" --name "$4" -w /app -v "$(pwd):/app" "$3"   
}

docker_c_run_always_in_network() {
    if [ -z "$1" ] || [ -z "$2" ] || [ -z "$3" ] || [ -z "$4" ] || [ -z "$5" ]; then
        echo "Usage: docker_run <originPort> <destinationPort> <image_name> <container_name> <network>"
        return 1
    fi
    sudo docker run -dp "$2:$1" --network "$5" --name "$4" -w /app -v "$(pwd):/app" "$3" tail -f /dev/null
}


docker_c_start() {
    if [ "$1" == "all" ]; then
        echo "Starting all stopped containers..."
        sudo docker start $(sudo docker ps -aq)
    else
        echo "Starting container: $1"
        sudo docker start "$1"
    fi
}

docker_c_stop() {
    if [ -z "$1" ]; then
        echo "Usage: docker_c_stop <container_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker stop $(sudo docker ps -q)
    else
        sudo docker stop "$1"
    fi
}

docker_c_restart() {
    if [ -z "$1" ]; then
        echo "Usage: docker_c_restart <container_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker restart $(sudo docker ps -q)
    else
        sudo docker restart "$1"
    fi
}

docker_c_delete() {
    if [ -z "$1" ]; then
        echo "Usage: docker_delete <container_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker rm $(sudo docker ps -aq)
    else
        sudo docker rm "$1"
    fi
}

docker_c_logs(){
    if [ -z "$1" ]; then
        echo "Usage: docker_c_logs <container_name_or_id>"
        return 1
    fi
    sudo docker logs -f "$1"
}

docker_c_enter(){
    if [ -z "$1" ]; then
        echo "Usage: docker_c_enter <container_name_or_id>"
        return 1
    fi
    sudo docker exec -it "$1" sh
}

docker_i(){
    sudo docker images
}

docker_i_build() {
    if [ -z "$1" ]; then
        echo "Usage: docker_build <image_name>"
        return 1
    fi
    sudo docker build --network=host -t "$1" .
}

docker_i_delete() {
    if [ -z "$1" ]; then
        echo "Usage: docker_delete_image <image_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker rmi $(sudo docker images -q)
    else
        sudo docker rmi "$1"
    fi
}

docker_i_delete_forced() {
    if [ -z "$1" ]; then
        echo "Usage: docker_delete_image <image_name_or_id> | all"
        return 1
    fi

    if [ "$1" = "all" ]; then
        sudo docker rmi -f $(sudo docker images -q)
    else
        sudo docker rmi -f "$1"
    fi
}

docker_i_compose() {
    sudo docker compose up
}

docker_i_compose_forced() {
    if [ -z "$1" ]; then
        echo "Usage: docker_i_compose_forced <service_name>"
        return 1
    fi
    sudo docker compose up --build --force-recreate --no-deps "$1"
}

docker_i_pull() {
    if [ -z "$1" ]; then
        echo "Usage: docker_i_pull <image_name> <version (opcional)>"
        return 1
    fi
    sudo docker image pull "$1:${2:-latest}"
}

docker_install() {
    OS=$1                 # 'debian' o 'ubuntu'
    TARGET_USER=${2:-$USER}  # usuario al que darle permisos (default: usuario actual)

    if [[ "$OS" != "debian" && "$OS" != "ubuntu" ]]; then
        echo "Error: Debes especificar 'debian' o 'ubuntu' como primer par√°metro."
        return 1
    fi

    if ! id -u "$TARGET_USER" >/dev/null 2>&1; then
        echo "Error: el usuario '$TARGET_USER' no existe en el sistema."
        return 1
    fi

    set -euo pipefail
    echo ">>> Instalando Docker en $OS para el usuario: $TARGET_USER"

    # Paquetes base y llave del repo oficial
    sudo apt-get update
    sudo apt-get install -y ca-certificates curl gnupg lsb-release
    sudo install -m 0755 -d /etc/apt/keyrings
    if [[ ! -f /etc/apt/keyrings/docker.asc ]]; then
        sudo curl -fsSL "https://download.docker.com/linux/$OS/gpg" -o /etc/apt/keyrings/docker.asc
        sudo chmod a+r /etc/apt/keyrings/docker.asc
    fi

    # Agregar repo estable
    CODENAME="$(. /etc/os-release && echo "$VERSION_CODENAME")"
    echo ">>> Usando codename: $CODENAME"
    echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/$OS $CODENAME stable" \
      | sudo tee /etc/apt/sources.list.d/docker.list >/dev/null

    # Instalar Docker + Buildx + Compose v2
    sudo apt-get update
    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

    # Habilitar y arrancar Docker
    sudo systemctl enable --now docker

    # Crear grupo docker si no existe y agregar usuario
    if ! getent group docker >/dev/null; then
        sudo groupadd docker
    fi
    sudo usermod -aG docker "$TARGET_USER"

    # Ajustar permisos del socket (para que funcione de inmediato en esta sesi√≥n)
    if [[ -S /var/run/docker.sock ]]; then
        sudo chown root:docker /var/run/docker.sock
        sudo chmod 660 /var/run/docker.sock
    fi

    # Verificaci√≥n b√°sica
    echo ">>> Verificaci√≥n:"
    docker --version || true
    docker compose version || true

    # Intentar ejecutar como el usuario objetivo sin re-login
    if sudo -u "$TARGET_USER" docker ps >/dev/null 2>&1; then
        echo "‚úÖ $TARGET_USER puede usar docker sin sudo."
    else
        # Intentar con 'sg docker' si est√° disponible (aplica el grupo en caliente)
        if command -v sg >/dev/null 2>&1; then
            if sudo -u "$TARGET_USER" sg docker -c 'docker ps' >/dev/null 2>&1; then
                echo "‚úÖ $TARGET_USER puede usar docker v√≠a 'sg docker' en esta sesi√≥n."
            else
                echo "‚ÑπÔ∏è A√∫n no es posible usar docker sin sudo en esta sesi√≥n."
            fi
        else
            echo "‚ÑπÔ∏è 'sg' no disponible; puede requerir re-login para aplicar el grupo."
        fi
        echo "üëâ Mientras tanto, puedes usar: sudo docker ..."
    fi

    echo "‚úÖ Instalaci√≥n completa. Si a√∫n no puedes usar 'docker' sin sudo, cierra y vuelve a entrar sesi√≥n de $TARGET_USER."
}

docker_clean(){
    sudo docker system prune -a --volumes
}

########################################################################################## GHOST

MAILGUN_USER="brad@sandbox27703646c4a5406f948c2ed685c84070.mailgun.org"
MAILGUN_API_KEY="27450cd34c15e02c3830faae0f41ff63-67bd41c2-c8b32c62"

ghost_terminal(){
    sudo docker exec -it ghost /bin/bash
}

install_jq_in_container() {
    echo "üîß Instalando jq dentro del contenedor Ghost..."
    sudo docker exec ghost bash -c "apt-get update && apt-get install -y jq"
}

replace_mail_config() {
    local config_file=$1

    echo "Verificando existencia del archivo en el contenedor: $config_file"
    sudo docker exec ghost ls "$config_file"

    if [ $? -ne 0 ]; then
        echo "El archivo $config_file no existe en el contenedor."
        return 1
    fi

    echo "Reemplazando la configuraci√≥n de mail en $config_file con jq..."

    sudo docker exec ghost bash -c "jq \
    '.mail = {
        transport: \"SMTP\",
        options: {
            service: \"Mailgun\",
            host: \"smtp.mailgun.org\",
            port: 587,
            secure: false,
            auth: {
                user: \"${MAILGUN_USER}\",
                pass: \"${MAILGUN_API_KEY}\"
            }
        }
    }' $config_file > /tmp/config.tmp && mv /tmp/config.tmp $config_file"

    echo "‚úÖ Configuraci√≥n de mail reemplazada usando jq."
}

ghost_run() {
    # Par√°metro: versi√≥n de Ghost
    GHOST_VERSION=$1

    # Nombre fijo para el contenedor y puerto est√°ndar
    CONTAINER_NAME="ghost"
    IMAGE_NAME="ghost:${GHOST_VERSION}"
    HOST_PORT=2368
    CONTAINER_PORT=2368

    echo "üß≠ Verificando existencia del contenedor '${CONTAINER_NAME}'..."

    if [ "$(sudo docker ps -a -q -f name=^/${CONTAINER_NAME}$)" ]; then
        echo "‚õî Contenedor '${CONTAINER_NAME}' encontrado. Deteniendo y eliminando..."
        sudo docker stop ${CONTAINER_NAME}
        sudo docker rm ${CONTAINER_NAME}
    else
        echo "‚ÑπÔ∏è No existe un contenedor llamado '${CONTAINER_NAME}'."
    fi

    echo "üßπ Limpiando vol√∫menes sin uso..."
    sudo docker volume prune -f

    echo "üì¶ Levantando Ghost ${GHOST_VERSION} en http://localhost:${HOST_PORT}..."
    sudo docker run -d \
        --name ${CONTAINER_NAME} \
        -e NODE_ENV=development \
        -p ${HOST_PORT}:${CONTAINER_PORT} \
        ${IMAGE_NAME}

    echo "‚úÖ Ghost ${GHOST_VERSION} corriendo en http://localhost:${HOST_PORT}"
}


cypress_run() {
    # Recibir la versi√≥n de Ghost como par√°metro
    VERSION=$1

    echo "üöÄ Ejecutando pruebas con Cypress usando la versi√≥n de Ghost ${VERSION}..."
    VERSION=$VERSION npm run test --workspace=e2e/misw-4103-cypress

    echo "üßπ Renombrando y moviendo archivos .png, y eliminando directorios vac√≠os..."

    find e2e/misw-4103-cypress/cypress/screenshots/$VERSION -mindepth 2 -type f -name "*.png" -exec bash -c '
      for file; do
        folder_path=$(dirname "$file")
        folder_name=$(basename "$folder_path")
        ext="${file##*.}"
        new_name="${folder_name}.${ext}"
        mv "$file" "e2e/misw-4103-cypress/cypress/screenshots/'"$VERSION"'/$new_name"
      done
    ' bash {} +

    find e2e/misw-4103-cypress/cypress/screenshots/$VERSION -mindepth 1 -type d -empty -delete
}




kraken_run(){
    npm run test --workspace=e2e/misw-4103-kraken
}

########################################################################################## KRAKEN
kraken_install(){
    npm install kraken-node -g
    kraken-node gen
    npm install kraken-node
}

kraken_run(){
    npm run test --workspace=e2e/misw-4103-kraken
}

kraken_reports_clear(){
    sudo rm -r /e2e/misw-4103-kraken/reports/
}
chromium_listen(){
    chromedriver --port=4444
}





########################################################################################## CYPRESS

cypress_install(){
    sudo npm install -g cypress
}

cypress_open(){
    cypress open
}

cypress_run_headed() {
    FOLDER=$1
    FILE=$2

    if [ "$FOLDER" == "all" ] && [ "$FILE" == "all" ]; then
        # Ejecutar todas las pruebas en modo headed
        sudo cypress run --headed
    elif [ "$FOLDER" == "all" ] && [ -n "$FILE" ]; then
        # Ejecutar un archivo espec√≠fico dentro de una carpeta en modo headed
        sudo cypress run --headed --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/$FILE.cy.js"
    elif [ -n "$FOLDER" ] && [ -n "$FILE" ]; then
        # Ejecutar un archivo espec√≠fico en una carpeta espec√≠fica en modo headed
        sudo cypress run --headed --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/$FILE.cy.js"
    else
        # Ejecutar todas las pruebas en una carpeta espec√≠fica en modo headed
        sudo cypress run --headed --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/*.cy.js"
    fi
}

cypress_run_headless() {
    FOLDER=$1
    FILE=$2

    if [ "$FOLDER" == "all" ] && [ "$FILE" == "all" ]; then
        # Ejecutar todas las pruebas en modo headless
        sudo cypress run --headless
    elif [ "$FOLDER" == "all" ] && [ -n "$FILE" ]; then
        # Ejecutar un archivo espec√≠fico dentro de una carpeta en modo headless
        sudo cypress run --headless --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/$FILE.cy.js"
    elif [ -n "$FOLDER" ] && [ -n "$FILE" ]; then
        # Ejecutar un archivo espec√≠fico en una carpeta espec√≠fica en modo headless
        sudo cypress run --headless --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/$FILE.cy.js"
    else
        # Ejecutar todas las pruebas en una carpeta espec√≠fica en modo headless
        sudo cypress run --headless --spec "/home/danielsierra34/MAESTRIA/MISW4103-Pruebas-automatizadas/CYPRESS/cypress/e2e/$FOLDER/*.cy.js"
    fi
}

agregar_x() {
    #!/bin/bash    
    carpeta="."     
    for archivo in "$carpeta"/*; do
      if [ -f "$archivo" ]; then
        nombre_base=$(basename "$archivo")
        nuevo_nombre="${nombre_base}.x"
        mv "$archivo" "$carpeta/$nuevo_nombre"
      fi
    done
}

saludar(){
    echo "Hola a todos"
}

quitar_x(){
    #!/bin/bash   
    carpeta="."  # Cambia esto por la ruta real    
    for archivo in "$carpeta"/*.x; do
      if [ -f "$archivo" ]; then
        nuevo_nombre="${archivo%.x}"
        mv "$archivo" "$nuevo_nombre"
      fi
    done
}
########################################################################################## OLLAMA
ollama_install(){
  sudo apt-get install zstd
  curl -fsSL https://ollama.com/install.sh | sh
}

ollama_pull () {
  # Cat√°logo curado (popular/√∫til) + descripciones.
  # Puedes ampliar/editar esta lista cuando quieras.

  if ! command -v ollama >/dev/null 2>&1; then
    echo "‚ùå 'ollama' no est√° instalado o no est√° en PATH."
    return 1
  fi

  # Lista de modelos (nombres tal como se usan en `ollama pull`)
  local models=(
    "gemma3:1b"
    "gemma2:2b"
    "gemma2:9b"
    "llama3.2:1b"
    "llama3.2:3b"
    "llama3.2:latest"
    "qwen2.5:7b"
    "qwen2.5:14b"
    "mistral:latest"
    "mixtral:8x7b"
    "phi3:mini"
    "phi3:medium"
    "codellama:7b"
    "starcoder2:7b"
    "deepseek-r1:7b"
    "deepseek-coder:6.7b"
  )

  # Descripciones (para qu√© sirve cada uno)
  # Nota: si alg√∫n nombre cambia en tu versi√≥n de Ollama, simplemente ajustas la key.
  declare -A desc=(
    ["gemma3:1b"]="Muy liviano. Ideal para aprender, hacer pruebas r√°pidas y experimentar prompting."
    ["gemma2:2b"]="Peque√±o y pr√°ctico. Buen equilibrio para tareas generales en m√°quina modesta."
    ["gemma2:9b"]="Mejor calidad que los peque√±os. General y bastante s√≥lido sin irse a tama√±os enormes."
    ["llama3.2:1b"]="Ultraligero. √ötil para experimentos r√°pidos; limitado en profundidad."
    ["llama3.2:3b"]="Peque√±o pero m√°s capaz. Buen modelo general para escritorio modesto."
    ["llama3.2:latest"]="General fuerte (seg√∫n disponibilidad local). Bueno para chat/razonamiento."
    ["qwen2.5:7b"]="Excelente para desarrollo y razonamiento. Muy buen ‚Äútodo terreno‚Äù para programar."
    ["qwen2.5:14b"]="Mejor calidad para c√≥digo/razonamiento. Recomendado si tu m√°quina lo aguanta."
    ["mistral:latest"]="R√°pido y eficiente. Bueno para respuestas cortas/medianas y chat."
    ["mixtral:8x7b"]="Muy buen rendimiento (MoE). Excelente calidad, pero m√°s pesado."
    ["phi3:mini"]="Modelo peque√±o para tareas b√°sicas y pruebas; r√°pido."
    ["phi3:medium"]="M√°s capaz que mini; buen balance para tareas generales."
    ["codellama:7b"]="Orientado a programaci√≥n (Code). √ötil si quieres foco en c√≥digo."
    ["starcoder2:7b"]="Muy bueno para c√≥digo (especialmente completaci√≥n y patrones de programaci√≥n)."
    ["deepseek-r1:7b"]="Fuerte en razonamiento (seg√∫n variante). √ötil para problemas l√≥gicos."
    ["deepseek-coder:6.7b"]="Fuerte para c√≥digo. Buen competidor para tareas de programaci√≥n."
  )

  echo "üåê Cat√°logo de modelos recomendados para descargar con Ollama"
  echo "   (Selecciona uno y lo instalo con 'ollama pull')"
  echo

  for i in "${!models[@]}"; do
    local m="${models[$i]}"
    local d="${desc[$m]:-Modelo popular (sin descripci√≥n en cat√°logo).}"
    printf "  [%d] %-20s ‚Äî %s\n" "$((i+1))" "$m" "$d"
  done

  echo
  read -rp "üëâ Selecciona un modelo para instalar (1-${#models[@]}) o Enter para cancelar: " choice
  if [ -z "${choice:-}" ]; then
    echo "‚ÑπÔ∏è  Cancelado."
    return 0
  fi

  if ! [[ "$choice" =~ ^[0-9]+$ ]] || (( choice < 1 || choice > ${#models[@]} )); then
    echo "‚ùå Selecci√≥n inv√°lida."
    return 1
  fi

  local selected="${models[$((choice-1))]}"
  echo
  echo "‚¨áÔ∏è  Instalando: $selected"
  ollama pull "$selected"
  echo "‚úÖ Instalado: $selected"
}


ollama_modelfile_generate () {
  # Nota: no uso "set -euo pipefail" para que si hay error lo veas y no muera en silencio

  _mf_print_hr() { printf '%*s\n' "${COLUMNS:-80}" '' | tr ' ' '-'; }
  _mf_title() { _mf_print_hr; echo "ü¶ô Ollama Modelfile Generator (sin whiptail)"; _mf_print_hr; }
  _mf_pause() { read -r -p "Enter para continuar..." _; }

  # options: array of "value|description" (name by reference) -> returns value in REPLY
  _mf_menu_vd() {
    local prompt="$1"
    local arr_name="$2"
    local -n _opts="$arr_name"

    echo
    echo "$prompt"
    local i=1
    for opt in "${_opts[@]}"; do
      local v="${opt%%|*}"
      local d="${opt#*|}"
      printf "  %2d) %-8s  %s\n" "$i" "$v" "$d"
      i=$((i+1))
    done

    while true; do
      read -r -p "Selecciona (1-${#_opts[@]}): " ans
      if [[ "$ans" =~ ^[0-9]+$ ]] && (( ans>=1 && ans<=${#_opts[@]} )); then
        local chosen="${_opts[$((ans-1))]}"
        REPLY="${chosen%%|*}"
        return 0
      fi
      echo "‚ùå Opci√≥n inv√°lida."
    done
  }

  # ===== Directories (HOME) =====
  local ROOT_DIR MF_DIR
  ROOT_DIR="$HOME/ollama"
  MF_DIR="$ROOT_DIR/modelfiles"
  mkdir -p "$MF_DIR" || { echo "‚ùå No pude crear $MF_DIR"; return 1; }

  _mf_title
  echo "üìÅ Carpeta destino: $MF_DIR"
  echo "‚ÑπÔ∏è  El Modelfile queda con FROM __BASE_MODEL__ para que lo reemplaces luego."
  _mf_pause

  # ===== Tipo / SYSTEM =====
  local TYPE SYSTEM_TEXT
  local -a TYPE_OPTS=(
    "chat|Conversaci√≥n general y asistencia cotidiana"
    "dev|Desarrollo/arquitectura: decisiones t√©cnicas y buenas pr√°cticas"
    "code|C√≥digo preciso y determinista (menos creatividad, m√°s exactitud)"
    "llm|An√°lisis acad√©mico y estudio de LLMs"
    "reason|Razonamiento estructurado paso a paso"
    "docs|Redacci√≥n t√©cnica/profesional con estructura"
    "promptlab|Experimentaci√≥n y pruebas de prompts"
  )
  _mf_menu_vd "Tipo de Modelfile (define el SYSTEM prompt):" TYPE_OPTS
  TYPE="$REPLY"

  case "$TYPE" in
    chat) SYSTEM_TEXT=$'Asistente general, claro y conciso.\nResponde en espa√±ol.' ;;
    dev) SYSTEM_TEXT=$'Asistente de desarrollo.\nSoluciones ejecutables, patrones y buenas pr√°cticas.' ;;
    code) SYSTEM_TEXT=$'Asistente de programaci√≥n.\nC√≥digo correcto, minimal y determinista.' ;;
    llm) SYSTEM_TEXT=$'Asistente acad√©mico para estudiar y analizar LLMs.' ;;
    reason) SYSTEM_TEXT=$'Asistente de razonamiento paso a paso y an√°lisis l√≥gico.' ;;
    docs) SYSTEM_TEXT=$'Redactor t√©cnico y acad√©mico, claro y estructurado.' ;;
    promptlab) SYSTEM_TEXT=$'Asistente para experimentar, evaluar y depurar prompts.' ;;
    *) SYSTEM_TEXT=$'Asistente general.' ;;
  esac

  # ===== Par√°metros =====
  local TEMP TOP_P TOP_K NUM_CTX NUM_PRED REP_PEN REP_LAST_N PEN_NL

  local -a TEMP_OPTS=(
    "0.2|Muy estable: ideal para l√≥gica/c√≥digo y salidas repetibles"
    "0.35|Equilibrado: precisi√≥n + naturalidad (recomendado general)"
    "0.6|M√°s variaci√≥n: conversaci√≥n e ideas con alternativas"
    "0.8|Creativo: brainstorming/estilo; m√°s riesgo de desviarse"
  )
  _mf_menu_vd "temperature (aleatoriedad): qu√© tan conservador vs creativo al elegir tokens" TEMP_OPTS
  TEMP="$REPLY"

  local -a TOP_P_OPTS=(
    "0.7|Muy conservador: recorta fuerte opciones raras"
    "0.8|Conservador: control alto con algo de variedad"
    "0.9|Balanceado: n√∫cleo t√≠pico (recomendado)"
    "0.95|Diverso: m√°s libertad, menos foco"
    "1.0|Sin recorte: deja pasar todo (controla con temperature)"
  )
  _mf_menu_vd "top_p (n√∫cleo): limita candidatos por probabilidad acumulada (nucleus sampling)" TOP_P_OPTS
  TOP_P="$REPLY"

  local -a TOP_K_OPTS=(
    "0|Desactivado: solo manda top_p (corte suave)"
    "40|Est√°ndar: buen control sin rigidez"
    "50|Equilibrado: algo m√°s de variedad"
    "100|Abierto: permite tokens raros/creativos"
  )
  _mf_menu_vd "top_k (corte duro): m√°ximo de K tokens candidatos por paso (0 = off)" TOP_K_OPTS
  TOP_K="$REPLY"

  local -a NUM_CTX_OPTS=(
    "2048|Corto: r√°pido/ligero; menos historial visible"
    "4096|Normal: buen balance (recomendado)"
    "8192|Largo: m√°s memoria; m√°s RAM/VRAM"
  )
  _mf_menu_vd "num_ctx (contexto): tokens m√°ximos de entrada (prompt + historial + instrucciones)" NUM_CTX_OPTS
  NUM_CTX="$REPLY"

  local -a NUM_PRED_OPTS=(
    "256|Corto: respuestas puntuales"
    "512|Medio: completo sin divagar (recomendado)"
    "1024|Largo: explicaciones extensas; m√°s costo/tiempo"
  )
  _mf_menu_vd "num_predict (salida): tokens m√°ximos que puede generar en una respuesta" NUM_PRED_OPTS
  NUM_PRED="$REPLY"

  local -a REP_PEN_OPTS=(
    "1.0|Sin penalizaci√≥n: puede repetir si se atasca"
    "1.10|Suave: reduce muletillas/loops (recomendado)"
    "1.20|Fuerte: corta loops agresivos; menos natural"
  )
  _mf_menu_vd "repeat_penalty (anti-repetici√≥n): castiga repetir tokens recientes" REP_PEN_OPTS
  REP_PEN="$REPLY"

  local -a REP_LAST_N_OPTS=(
    "64|Ventana corta: penaliza repetici√≥n inmediata"
    "128|Ventana media: balance ideal (recomendado)"
    "256|Ventana larga: evita repetici√≥n a m√°s largo plazo"
  )
  _mf_menu_vd "repeat_last_n (ventana): cu√°ntos tokens hacia atr√°s se consideran para penalizaci√≥n" REP_LAST_N_OPTS
  REP_LAST_N="$REPLY"

  local -a PEN_NL_OPTS=(
    "false|Formato libre: mejor para markdown, listas y c√≥digo"
    "true|Texto compacto: menos saltos de l√≠nea"
  )
  _mf_menu_vd "penalize_newline (saltos de l√≠nea): reduce la tendencia a separar por l√≠neas" PEN_NL_OPTS
  PEN_NL="$REPLY"

  # ===== Nombre (√∫nico input escrito) =====
  echo
  local NAME
  read -r -p "Nombre del Modelfile (√∫nico campo que se escribe) [my-${TYPE}]: " NAME
  NAME="${NAME:-my-${TYPE}}"
  NAME="$(echo "$NAME" | tr -cd 'a-zA-Z0-9._-')"
  [[ -z "$NAME" ]] && { echo "‚ùå Nombre inv√°lido."; return 1; }

  local FILE="$MF_DIR/Modelfile.${NAME}"
  if [[ -e "$FILE" ]]; then
    echo "‚ö†Ô∏è Ya existe: $FILE"
    read -r -p "¬øSobrescribir? (y/N): " yn
    [[ "${yn,,}" == "y" ]] || { echo "Cancelado."; return 1; }
  fi

  cat > "$FILE" <<EOF
FROM __BASE_MODEL__

SYSTEM """
${SYSTEM_TEXT}
"""

PARAMETER temperature ${TEMP}
PARAMETER top_p ${TOP_P}
PARAMETER top_k ${TOP_K}
PARAMETER num_ctx ${NUM_CTX}
PARAMETER num_predict ${NUM_PRED}
PARAMETER repeat_penalty ${REP_PEN}
PARAMETER repeat_last_n ${REP_LAST_N}
PARAMETER penalize_newline ${PEN_NL}
EOF

  echo
  _mf_print_hr
  echo "‚úÖ Modelfile creado correctamente:"
  echo "   $FILE"
  _mf_print_hr
}











alias venv_iniciar='python3 -m venv .venv'
alias venv_activar='source .venv/bin/activate'
alias venv_desactivar='deactivate'

alias bitnami_reiniciar='sudo /opt/bitnami/ctlscript.sh restart'
alias bitnami_bncert='sudo /opt/bitnami/bncert-tool'
alias bitnami_phpini='sudo nano /opt/bitnami/php/etc/php.ini'
alias errorlog='cat  /opt/bitnami/apache2/logs/error_log'
alias clear-errorlog='sudo truncate -s0  /opt/bitnami/apache2/logs/error_log'

alias bashrc='. ~/.bashrc'

